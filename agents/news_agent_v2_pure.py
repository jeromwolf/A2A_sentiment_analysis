#!/usr/bin/env python3
"""News Agent V2 - A2A í”„ë¡œí† ì½œ ê¸°ë°˜ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì—ì´ì „íŠ¸"""

import os
import json
import httpx
from typing import List, Dict, Optional
from datetime import datetime, timedelta
from dotenv import load_dotenv
import logging
# from googletrans import Translator  # ì„ì‹œë¡œ ë¹„í™œì„±í™”
from a2a_core.base.base_agent import BaseAgent
from a2a_core.protocols.message import A2AMessage, MessageType
from pydantic import BaseModel

class NewsRequest(BaseModel):
    ticker: str

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class NewsAgentV2(BaseAgent):
    """ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ A2A ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        super().__init__(
            name="News Agent V2 Pure",
            description="ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ìˆœìˆ˜ V2 A2A ì—ì´ì „íŠ¸",
            port=8207
        )
        
        # API í‚¤ ì„¤ì •
        self.finnhub_api_key = os.getenv("FINNHUB_API_KEY")
        self.news_api_key = os.getenv("NEWS_API_KEY")
        
        # ë²ˆì—­ê¸° ì´ˆê¸°í™” (ì„ì‹œë¡œ ë¹„í™œì„±í™”)
        # self.translator = Translator()
        
        # íšŒì‚¬ëª… - í‹°ì»¤ ë§¤í•‘
        self.ticker_to_company = {
            "AAPL": "Apple",
            "GOOGL": "Google", 
            "MSFT": "Microsoft",
            "AMZN": "Amazon",
            "META": "Meta",
            "TSLA": "Tesla",
            "NVDA": "NVIDIA"
        }
        
        # ê¸ˆìœµ ìš©ì–´ ì‚¬ì „ (ì˜ì–´ -> í•œêµ­ì–´)
        self.finance_terms = {
            "revenue": "ë§¤ì¶œ",
            "earnings": "ìˆ˜ìµ",
            "profit": "ì´ìµ",
            "loss": "ì†ì‹¤",
            "growth": "ì„±ì¥",
            "decline": "í•˜ë½",
            "surge": "ê¸‰ë“±",
            "plunge": "ê¸‰ë½",
            "rally": "ìƒìŠ¹",
            "bear market": "ì•½ì„¸ì¥",
            "bull market": "ê°•ì„¸ì¥",
            "volatility": "ë³€ë™ì„±",
            "dividend": "ë°°ë‹¹ê¸ˆ",
            "acquisition": "ì¸ìˆ˜",
            "merger": "í•©ë³‘",
            "IPO": "ê¸°ì—…ê³µê°œ",
            "stake": "ì§€ë¶„",
            "shares": "ì£¼ì‹",
            "stock": "ì£¼ì‹",
            "market cap": "ì‹œê°€ì´ì•¡",
            "valuation": "ê°€ì¹˜í‰ê°€",
            "forecast": "ì „ë§",
            "guidance": "ê°€ì´ë˜ìŠ¤",
            "outlook": "ì „ë§",
            "beat": "ìƒíšŒ",
            "miss": "í•˜íšŒ",
            "estimate": "ì˜ˆìƒì¹˜",
            "consensus": "ì»¨ì„¼ì„œìŠ¤",
            "upgrade": "ìƒí–¥",
            "downgrade": "í•˜í–¥",
            "target price": "ëª©í‘œì£¼ê°€",
            "buy": "ë§¤ìˆ˜",
            "sell": "ë§¤ë„",
            "hold": "ë³´ìœ ",
            "outperform": "ì‹œì¥ìˆ˜ìµë¥  ìƒíšŒ",
            "underperform": "ì‹œì¥ìˆ˜ìµë¥  í•˜íšŒ"
        }
        
        # HTTP ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
        self._setup_http_endpoints()
        
    def _setup_http_endpoints(self):
        """HTTP ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •"""
        @self.app.post("/collect_news_data")
        async def collect_news_data(request: NewsRequest):
            """HTTP ì—”ë“œí¬ì¸íŠ¸ë¡œ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘"""
            ticker = request.ticker
            logger.info(f"ğŸ“° HTTP ìš”ì²­ìœ¼ë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘: {ticker}")
            
            # ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
            news_data = await self._collect_news_data(ticker)
            
            return {
                "data": news_data,
                "count": len(news_data),
                "source": "news",
                "log_message": f"âœ… {ticker} ë‰´ìŠ¤ {len(news_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ"
            }
        
    async def on_start(self):
        """ì—ì´ì „íŠ¸ ì‹œì‘ ì‹œ í˜¸ì¶œ"""
        # ëŠ¥ë ¥ ë“±ë¡
        await self.register_capability({
            "name": "news_data_collection",
            "version": "2.0",
            "description": "ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘",
            "input_schema": {
                "type": "object",
                "properties": {
                    "ticker": {"type": "string", "description": "ì£¼ì‹ í‹°ì»¤"}
                },
                "required": ["ticker"]
            }
        })
        
    async def on_stop(self):
        """ì—ì´ì „íŠ¸ ì¢…ë£Œ ì‹œ í˜¸ì¶œ"""
        pass
        
    async def handle_message(self, message: A2AMessage):
        """ë©”ì‹œì§€ ì²˜ë¦¬"""
        logger.info(f"ğŸ” ë©”ì‹œì§€ ìˆ˜ì‹  - Type: {message.header.message_type}, Action: {message.body.get('action')}")
        
        if message.header.message_type == MessageType.REQUEST:
            action = message.body.get("action")
            
            if action == "news_data_collection":
                await self._handle_news_collection(message)
            else:
                await self.reply_to_message(
                    message, 
                    {"error": f"Unknown action: {action}"}, 
                    success=False
                )
                
    async def _handle_news_collection(self, message: A2AMessage):
        """ë‰´ìŠ¤ ìˆ˜ì§‘ ìš”ì²­ ì²˜ë¦¬"""
        try:
            payload = message.body.get("payload", {})
            ticker = payload.get("ticker")
            
            if not ticker:
                await self.reply_to_message(
                    message,
                    {"error": "Ticker is required"},
                    success=False
                )
                return
                
            logger.info(f"ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘: {ticker}")
            
            # ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
            news_data = await self._collect_news_data(ticker)
            
            # ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ì´ë²¤íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            await self.broadcast_event(
                event_type="data_collected",
                event_data={
                    "source": "news",
                    "ticker": ticker,
                    "count": len(news_data),
                    "timestamp": datetime.now().isoformat()
                }
            )
            
            # ì‘ë‹µ ì „ì†¡
            result = {
                "data": news_data,
                "source": "news",
                "count": len(news_data)
            }
            
            logger.info(f"âœ… ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {len(news_data)}ê°œ í•­ëª©")
            await self.reply_to_message(message, result, success=True)
            
        except Exception as e:
            logger.error(f"âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            await self.reply_to_message(
                message,
                {"error": str(e)},
                success=False
            )
            
    async def _collect_news_data(self, ticker: str) -> List[Dict]:
        """ì‹¤ì œ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘"""
        company_name = self.ticker_to_company.get(ticker.upper(), ticker)
        all_news = []
        
        # Finnhub APIë¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ìˆ˜ì§‘
        if self.finnhub_api_key:
            finnhub_news = await self._collect_finnhub_news(ticker)
            all_news.extend(finnhub_news)
            
        # NewsAPI ì‚¬ìš© (NEWS_API_KEYê°€ ìˆëŠ” ê²½ìš°)
        if self.news_api_key and len(all_news) < 5:
            newsapi_news = await self._collect_newsapi_news(ticker, company_name)
            all_news.extend(newsapi_news)
            
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        unique_news = self._remove_duplicates(all_news)
        sorted_news = sorted(unique_news, key=lambda x: x.get("published_date", ""), reverse=True)
        
        return sorted_news[:10]  # ìµœëŒ€ 10ê°œ
        
    async def _collect_finnhub_news(self, ticker: str) -> List[Dict]:
        """Finnhub APIë¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        news_items = []
        
        try:
            async with httpx.AsyncClient() as client:
                to_date = datetime.now()
                from_date = to_date - timedelta(days=7)
                
                response = await client.get(
                    "https://finnhub.io/api/v1/company-news",
                    params={
                        "symbol": ticker,
                        "from": from_date.strftime("%Y-%m-%d"),
                        "to": to_date.strftime("%Y-%m-%d"),
                        "token": self.finnhub_api_key
                    }
                )
                
                if response.status_code == 200:
                    data = response.json()
                    
                    for item in data[:5]:
                        # ì›ë³¸ ì œëª©ê³¼ ë‚´ìš©
                        original_title = item.get("headline", "")
                        original_content = item.get("summary", "")
                        
                        # ë²ˆì—­
                        translated_title = await self._translate_text(original_title)
                        translated_content = await self._translate_text(original_content)
                        
                        news_items.append({
                            "title": original_title,
                            "title_kr": translated_title,
                            "content": original_content,
                            "content_kr": translated_content,
                            "url": item.get("url", ""),
                            "source": item.get("source", "Finnhub"),
                            "published_date": datetime.fromtimestamp(item.get("datetime", 0)).isoformat(),
                            "sentiment": "neutral"
                        })
                        
        except Exception as e:
            logger.error(f"Finnhub API ì˜¤ë¥˜: {e}")
            
        return news_items
        
    async def _collect_newsapi_news(self, ticker: str, company_name: str) -> List[Dict]:
        """NewsAPIë¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        news_items = []
        
        try:
            async with httpx.AsyncClient() as client:
                # NewsAPIëŠ” ì£¼ì‹ í‹°ì»¤ë³´ë‹¤ íšŒì‚¬ëª…ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” ê²ƒì´ íš¨ê³¼ì 
                query = f"{company_name} OR {ticker}"
                
                response = await client.get(
                    "https://newsapi.org/v2/everything",
                    params={
                        "q": query,
                        "apiKey": self.news_api_key,
                        "language": "en",
                        "sortBy": "relevancy",
                        "pageSize": 10
                    }
                )
                
                if response.status_code == 200:
                    data = response.json()
                    articles = data.get("articles", [])
                    
                    for article in articles[:5]:
                        # ì›ë³¸ ì œëª©ê³¼ ë‚´ìš©
                        original_title = article.get("title", "")
                        original_content = article.get("description", "") or article.get("content", "")
                        
                        # ë²ˆì—­
                        translated_title = await self._translate_text(original_title)
                        translated_content = await self._translate_text(original_content)
                        
                        news_items.append({
                            "title": original_title,
                            "title_kr": translated_title,
                            "content": original_content,
                            "content_kr": translated_content,
                            "url": article.get("url", ""),
                            "source": article.get("source", {}).get("name", "NewsAPI"),
                            "published_date": article.get("publishedAt", ""),
                            "sentiment": "neutral"
                        })
                else:
                    logger.error(f"NewsAPI ì˜¤ë¥˜: {response.status_code}")
                    
        except Exception as e:
            logger.error(f"NewsAPI í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            
        return news_items
        
    def _generate_mock_news(self, ticker: str, company_name: str) -> List[Dict]:
        """ëª¨ì˜ ë‰´ìŠ¤ ë°ì´í„° ìƒì„± - í‹°ì»¤ë³„ë¡œ ë‹¤ë¥¸ ë‚´ìš©"""
        now = datetime.now()
        
        # í‹°ì»¤ë³„ íŠ¹í™”ëœ ë‰´ìŠ¤
        ticker_specific_news = {
            "AAPL": [
                {
                    "title": "ì• í”Œ, ì°¨ì„¸ëŒ€ M4 ì¹© ë§¥ë¶ í”„ë¡œ ì¶œì‹œ ì„ë°•",
                    "content": "ì• í”Œì´ ì°¨ì„¸ëŒ€ M4 ì¹©ì„ íƒ‘ì¬í•œ ë§¥ë¶ í”„ë¡œë¥¼ ê³§ ì¶œì‹œí•  ì˜ˆì •ì…ë‹ˆë‹¤. ì„±ëŠ¥ì´ ê¸°ì¡´ ëŒ€ë¹„ 40% í–¥ìƒë˜ì–´ í¬ë¦¬ì—ì´í„°ë“¤ì˜ ê´€ì‹¬ì„ ëŒê³  ìˆìŠµë‹ˆë‹¤.",
                    "sentiment": "positive",
                    "source": "Bloomberg"
                },
                {
                    "title": "ì• í”Œ, ì¤‘êµ­ ì‹œì¥ì—ì„œ í™”ì›¨ì´ì— ë°€ë ¤ ì ìœ ìœ¨ í•˜ë½",
                    "content": "ì• í”Œì´ ì¤‘êµ­ ìŠ¤ë§ˆíŠ¸í° ì‹œì¥ì—ì„œ í™”ì›¨ì´ì˜ ê³µì„¸ì— ë°€ë ¤ ì ìœ ìœ¨ì´ í•˜ë½í–ˆìŠµë‹ˆë‹¤. í˜„ì§€í™” ì „ëµ ë¶€ì¬ê°€ ì›ì¸ìœ¼ë¡œ ì§€ì ë©ë‹ˆë‹¤.",
                    "sentiment": "negative",
                    "source": "Financial Times"
                },
                {
                    "title": "ì• í”Œ ì„œë¹„ìŠ¤ ë¶€ë¬¸ ë§¤ì¶œ 200ì–µ ë‹¬ëŸ¬ ëŒíŒŒ ì „ë§",
                    "content": "ì• í”Œì˜ ì„œë¹„ìŠ¤ ë¶€ë¬¸ ë§¤ì¶œì´ ì˜¬í•´ 200ì–µ ë‹¬ëŸ¬ë¥¼ ëŒíŒŒí•  ì „ë§ì…ë‹ˆë‹¤. ì• í”Œ ë®¤ì§, TV+ êµ¬ë…ì ì¦ê°€ê°€ ì£¼ìš” ë™ë ¥ì…ë‹ˆë‹¤.",
                    "sentiment": "positive",
                    "source": "Reuters"
                },
                {
                    "title": "EU, ì• í”Œì— ì•±ìŠ¤í† ì–´ ë…ì  ê´€ë ¨ ì¶”ê°€ ê·œì œ ê²€í† ",
                    "content": "EUê°€ ì• í”Œì˜ ì•±ìŠ¤í† ì–´ ì •ì±…ì— ëŒ€í•´ ì¶”ê°€ ê·œì œë¥¼ ê²€í† í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìˆ˜ìˆ˜ë£Œ ì •ì±… ë³€ê²½ ì••ë°•ì´ ê±°ì„¸ì§ˆ ì „ë§ì…ë‹ˆë‹¤.",
                    "sentiment": "negative",
                    "source": "Wall Street Journal"
                },
                {
                    "title": "ì• í”Œ, ì¸ë„ ìƒì‚° ë¹„ì¤‘ 25%ë¡œ í™•ëŒ€ ê³„íš",
                    "content": "ì• í”Œì´ ì¸ë„ ìƒì‚° ë¹„ì¤‘ì„ í˜„ì¬ 7%ì—ì„œ 25%ê¹Œì§€ í™•ëŒ€í•  ê³„íšì…ë‹ˆë‹¤. ì¤‘êµ­ ì˜ì¡´ë„ë¥¼ ë‚®ì¶”ê¸° ìœ„í•œ ì „ëµìœ¼ë¡œ í’€ì´ë©ë‹ˆë‹¤.",
                    "sentiment": "neutral",
                    "source": "CNBC"
                }
            ],
            "TSLA": [
                {
                    "title": "í…ŒìŠ¬ë¼, ì‚¬ì´ë²„íŠ¸ëŸ­ ì£¼ê°„ ìƒì‚° 1000ëŒ€ ëŒíŒŒ",
                    "content": "í…ŒìŠ¬ë¼ê°€ ì‚¬ì´ë²„íŠ¸ëŸ­ ì£¼ê°„ ìƒì‚°ëŸ‰ 1000ëŒ€ë¥¼ ëŒíŒŒí–ˆìŠµë‹ˆë‹¤. ì´ˆê¸° ìƒì‚° ëª©í‘œë¥¼ ë‹¬ì„±í•˜ë©° ìˆ˜ìµì„± ê°œì„ ì´ ê¸°ëŒ€ë©ë‹ˆë‹¤.",
                    "sentiment": "positive",
                    "source": "Reuters"
                },
                {
                    "title": "í…ŒìŠ¬ë¼ FSD, ì•ˆì „ì„± ë¬¸ì œë¡œ NHTSA ì¡°ì‚¬ ì°©ìˆ˜",
                    "content": "ë¯¸êµ­ ë„ë¡œêµí†µì•ˆì „ì²­(NHTSA)ì´ í…ŒìŠ¬ë¼ FSDì˜ ì•ˆì „ì„± ë¬¸ì œë¡œ ì¡°ì‚¬ì— ì°©ìˆ˜í–ˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ê±´ì˜ ì‚¬ê³ ê°€ ë³´ê³ ëœ ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡ŒìŠµë‹ˆë‹¤.",
                    "sentiment": "negative",
                    "source": "Bloomberg"
                },
                {
                    "title": "í…ŒìŠ¬ë¼, ë©•ì‹œì½” ê¸°ê°€íŒ©í† ë¦¬ ê±´ì„¤ ì¬ê°œ",
                    "content": "í…ŒìŠ¬ë¼ê°€ ë©•ì‹œì½” ê¸°ê°€íŒ©í† ë¦¬ ê±´ì„¤ì„ ì¬ê°œí–ˆìŠµë‹ˆë‹¤. 2025ë…„ ê°€ë™ì„ ëª©í‘œë¡œ í•˜ë©° ì—°ê°„ 100ë§ŒëŒ€ ìƒì‚° ëŠ¥ë ¥ì„ ê°–ì¶œ ì˜ˆì •ì…ë‹ˆë‹¤.",
                    "sentiment": "positive",
                    "source": "Financial Times"
                },
                {
                    "title": "í…ŒìŠ¬ë¼ ì—ë„ˆì§€ ì‚¬ì—…ë¶€, ë¶„ê¸° ë§¤ì¶œ 15ì–µ ë‹¬ëŸ¬ ë‹¬ì„±",
                    "content": "í…ŒìŠ¬ë¼ ì—ë„ˆì§€ ì‚¬ì—…ë¶€ê°€ ë¶„ê¸° ë§¤ì¶œ 15ì–µ ë‹¬ëŸ¬ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ë©”ê°€íŒ© ìˆ˜ìš” ì¦ê°€ê°€ ì£¼ìš” ì„±ì¥ ë™ë ¥ìœ¼ë¡œ ì‘ìš©í–ˆìŠµë‹ˆë‹¤.",
                    "sentiment": "positive",
                    "source": "Wall Street Journal"
                },
                {
                    "title": "í…ŒìŠ¬ë¼, ìœ ëŸ½ ì „ê¸°ì°¨ ì‹œì¥ ì ìœ ìœ¨ ì†Œí­ í•˜ë½",
                    "content": "í…ŒìŠ¬ë¼ì˜ ìœ ëŸ½ ì „ê¸°ì°¨ ì‹œì¥ ì ìœ ìœ¨ì´ ì†Œí­ í•˜ë½í–ˆìŠµë‹ˆë‹¤. í˜„ì§€ ë¸Œëœë“œë“¤ì˜ ê²½ìŸë ¥ ê°•í™”ê°€ ì›ì¸ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤.",
                    "sentiment": "neutral",
                    "source": "CNBC"
                }
            ],
            "NVDA": [
                {
                    "title": "ì—”ë¹„ë””ì•„, ì°¨ì„¸ëŒ€ AI ì¹© 'Blackwell' ëŒ€ëŸ‰ ìƒì‚° ì‹œì‘",
                    "content": "ì—”ë¹„ë””ì•„ê°€ ì°¨ì„¸ëŒ€ AI ì¹© 'Blackwell'ì˜ ëŒ€ëŸ‰ ìƒì‚°ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤. ì„±ëŠ¥ì´ ê¸°ì¡´ ëŒ€ë¹„ 2.5ë°° í–¥ìƒë˜ì–´ ìˆ˜ìš”ê°€ í­ë°œì ì¼ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.",
                    "sentiment": "positive",
                    "source": "Bloomberg"
                },
                {
                    "title": "ë¯¸êµ­, ì—”ë¹„ë””ì•„ ì¤‘êµ­ ìˆ˜ì¶œ ì¶”ê°€ ì œì¬ ê²€í† ",
                    "content": "ë¯¸êµ­ ì •ë¶€ê°€ ì—”ë¹„ë””ì•„ì˜ ì¤‘êµ­ ìˆ˜ì¶œì— ëŒ€í•´ ì¶”ê°€ ì œì¬ë¥¼ ê²€í† í•˜ê³  ìˆìŠµë‹ˆë‹¤. AI ì¹© ê¸°ìˆ  ìœ ì¶œ ìš°ë ¤ê°€ ì œê¸°ë˜ê³  ìˆìŠµë‹ˆë‹¤.",
                    "sentiment": "negative",
                    "source": "Financial Times"
                },
                {
                    "title": "ì—”ë¹„ë””ì•„, ì£¼ìš” í´ë¼ìš°ë“œ ì—…ì²´ì™€ 5ë…„ ê³µê¸‰ ê³„ì•½ ì²´ê²°",
                    "content": "ì—”ë¹„ë””ì•„ê°€ ì£¼ìš” í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì—…ì²´ë“¤ê³¼ 5ë…„ê°„ AI ì¹© ê³µê¸‰ ê³„ì•½ì„ ì²´ê²°í–ˆìŠµë‹ˆë‹¤. ê³„ì•½ ê·œëª¨ëŠ” 500ì–µ ë‹¬ëŸ¬ì— ë‹¬í•©ë‹ˆë‹¤.",
                    "sentiment": "positive",
                    "source": "Reuters"
                },
                {
                    "title": "ì—”ë¹„ë””ì•„ CEO, 'AI ê±°í’ˆë¡ ' ì¼ì¶•",
                    "content": "ì  ìŠ¨ í™© ì—”ë¹„ë””ì•„ CEOê°€ AI ê±°í’ˆë¡ ì„ ì¼ì¶•í–ˆìŠµë‹ˆë‹¤. AI í˜ëª…ì€ ì´ì œ ì‹œì‘ ë‹¨ê³„ë¼ë©° ì¥ê¸° ì„±ì¥ì„ í™•ì‹ í•œë‹¤ê³  ë°í˜”ìŠµë‹ˆë‹¤.",
                    "sentiment": "positive",
                    "source": "Wall Street Journal"
                },
                {
                    "title": "ê²½ìŸì‚¬ë“¤, ì—”ë¹„ë””ì•„ CUDA ë…ì ì— ëŒ€í•­ ì—°í•© ê²°ì„±",
                    "content": "AMD, ì¸í…” ë“±ì´ ì—”ë¹„ë””ì•„ì˜ CUDA ë…ì ì— ëŒ€í•­í•˜ëŠ” ê°œë°©í˜• í‘œì¤€ ì—°í•©ì„ ê²°ì„±í–ˆìŠµë‹ˆë‹¤. ì‹œì¥ ê²½ìŸ êµ¬ë„ì— ë³€í™”ê°€ ì˜ˆìƒë©ë‹ˆë‹¤.",
                    "sentiment": "neutral",
                    "source": "CNBC"
                }
            ]
        }
        
        # ê¸°ë³¸ ë‰´ìŠ¤ í…œí”Œë¦¿
        default_news = [
            {
                "title": f"{company_name} ì£¼ê°€ ë³€ë™ì„± í™•ëŒ€",
                "content": f"{company_name}ì˜ ì£¼ê°€ê°€ ìµœê·¼ ë³€ë™ì„±ì´ í™•ëŒ€ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì‹œì¥ ì°¸ê°€ìë“¤ì˜ ê´€ë§ì„¸ê°€ ì´ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤.",
                "sentiment": "neutral",
                "source": "Reuters"
            },
            {
                "title": f"{company_name}, ì‹ ê·œ ì‚¬ì—… ì§„ì¶œ ê²€í† ",
                "content": f"{company_name}ì´ ì‹ ê·œ ì‚¬ì—… ì§„ì¶œì„ ê²€í† í•˜ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡ŒìŠµë‹ˆë‹¤. êµ¬ì²´ì ì¸ ê³„íšì€ ì•„ì§ ê³µê°œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "sentiment": "neutral",
                "source": "Bloomberg"
            }
        ]
        
        # í‹°ì»¤ì— ë§ëŠ” ë‰´ìŠ¤ ì„ íƒ
        news_templates = ticker_specific_news.get(ticker, default_news)
        
        news_items = []
        for i, template in enumerate(news_templates[:5]):  # ìµœëŒ€ 5ê°œ
            news_items.append({
                "title": template["title"],
                "title_kr": template["title"],  # ëª¨ì˜ ë°ì´í„°ëŠ” ì´ë¯¸ í•œê¸€
                "content": template["content"],
                "content_kr": template["content"],  # ëª¨ì˜ ë°ì´í„°ëŠ” ì´ë¯¸ í•œê¸€
                "url": f"https://example.com/news/{ticker}-{i}",
                "source": template["source"],
                "published_date": (now - timedelta(hours=i*6)).isoformat(),
                "sentiment": template.get("sentiment", "neutral")
            })
            
        return news_items
        
    def _remove_duplicates(self, news_list: List[Dict]) -> List[Dict]:
        """ì¤‘ë³µ ë‰´ìŠ¤ ì œê±°"""
        seen_titles = set()
        unique_news = []
        
        for item in news_list:
            title = item.get("title", "").lower().strip()
            if title and title not in seen_titles:
                seen_titles.add(title)
                unique_news.append(item)
                
        return unique_news
    
    async def _translate_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­"""
        if not text:
            return ""
            
        try:
            # ë¨¼ì € ê¸ˆìœµ ìš©ì–´ ì‚¬ì „ìœ¼ë¡œ ì¹˜í™˜
            translated = text
            for eng_term, kor_term in self.finance_terms.items():
                # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ì¹˜í™˜
                import re
                pattern = re.compile(re.escape(eng_term), re.IGNORECASE)
                translated = pattern.sub(kor_term, translated)
            
            # Google Translate APIë¡œ ì „ì²´ ë²ˆì—­ (ì„ì‹œë¡œ í‚¤ì›Œë“œ ê¸°ë°˜ ë²ˆì—­ë§Œ ì‚¬ìš©)
            # result = self.translator.translate(translated, src='en', dest='ko')
            # return result.text
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ë²ˆì—­ë§Œ ë°˜í™˜
            # ê¸ˆìœµ ìš©ì–´ê°€ í•˜ë‚˜ë¼ë„ ì¹˜í™˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if translated != text:
                return translated
            else:
                return text[:100] + "..."  # ì›ë¬¸ ì¼ë¶€ ë°˜í™˜
            
        except Exception as e:
            logger.warning(f"ë²ˆì—­ ì˜¤ë¥˜: {e}")
            # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
            return text

# ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
agent = NewsAgentV2()

# BaseAgentì˜ appì„ ì‚¬ìš©
app = agent.app

# ì•± ì‹œì‘ ì‹œ ì—ì´ì „íŠ¸ ì‹œì‘
@app.on_event("startup")
async def startup():
    print("ğŸš€ News Agent V2 Pure ì‹œì‘ ì¤‘...")
    await agent.start()

# ì•± ì¢…ë£Œ ì‹œ ì—ì´ì „íŠ¸ ì •ë¦¬
@app.on_event("shutdown")
async def shutdown():
    await agent.stop()

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8207)