"""
SEC Agent V2 - ìˆœìˆ˜ A2A êµ¬í˜„

SEC ê³µì‹œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ë…ë¦½ì ì¸ V2 ì—ì´ì „íŠ¸
V1 ì˜ì¡´ì„± ì—†ì´ ì§ì ‘ SEC EDGAR API í˜¸ì¶œ
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import httpx
import asyncio
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from dotenv import load_dotenv
import re
from bs4 import BeautifulSoup
import json

from a2a_core.base.base_agent import BaseAgent
from a2a_core.protocols.message import A2AMessage, MessageType
from pydantic import BaseModel
from fastapi import Depends

# ì„¤ì • ê´€ë¦¬ì ë° ì»¤ìŠ¤í…€ ì—ëŸ¬ ì„í¬íŠ¸
from utils.config_manager import config
from utils.errors import APIRateLimitError, APITimeoutError, DataNotFoundError
from utils.auth import verify_api_key
from utils.translation_manager import translation_manager, translate_text

load_dotenv(override=True)

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class SECRequest(BaseModel):
    ticker: str


class SECAgentV2(BaseAgent):
    """SEC ê³µì‹œ ìˆ˜ì§‘ V2 ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        # ì„¤ì •ì—ì„œ ì—ì´ì „íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        agent_config = config.get_agent_config("sec")
        
        super().__init__(
            name=agent_config.get("name", "SEC Agent V2"),
            description="SEC ê³µì‹œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” A2A ì—ì´ì „íŠ¸",
            port=agent_config.get("port", 8210),
            registry_url="http://localhost:8001"
        )
        
        # API ì„¤ì •
        self.user_agent = config.get_env("SEC_API_USER_AGENT", "A2A-Agent/1.0")
        self.max_filings = int(config.get_env("MAX_SEC_FILINGS", "20"))
        
        # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        self.timeout = agent_config.get("timeout", 60)
        
        # ë”ë¯¸ ë°ì´í„° ì‚¬ìš© ì—¬ë¶€
        self.use_mock_data = config.is_mock_data_enabled()
        
        # ìºì‹œ ì„¤ì •
        self.cik_cache = {}  # CIK ë§¤í•‘ ìºì‹œ
        
        # HTTP ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
        self._setup_http_endpoints()
        
    async def on_start(self):
        """ì—ì´ì „íŠ¸ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
        # ëŠ¥ë ¥ ë“±ë¡
        await self.register_capability({
            "name": "sec_data_collection",
            "version": "2.0",
            "description": "SEC ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘",
            "input_schema": {
                "type": "object",
                "properties": {
                    "ticker": {"type": "string", "description": "ì£¼ì‹ í‹°ì»¤"}
                },
                "required": ["ticker"]
            },
            "output_schema": {
                "type": "object",
                "properties": {
                    "data": {"type": "array"},
                    "count": {"type": "integer"},
                    "source": {"type": "string"}
                }
            }
        })
        
        print("âœ… SEC Agent V2 ì´ˆê¸°í™” ì™„ë£Œ")
        
    async def on_stop(self):
        """ì—ì´ì „íŠ¸ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
        print("ğŸ›‘ SEC Agent V2 ì¢…ë£Œ ì¤‘...")
        
    async def handle_message(self, message: A2AMessage):
        """ë©”ì‹œì§€ ì²˜ë¦¬"""
        try:
            if message.header.message_type == MessageType.REQUEST:
                action = message.body.get("action")
                
                if action == "sec_data_collection":
                    await self._handle_sec_collection(message)
                else:
                    await self.reply_to_message(
                        message,
                        result={"error": f"Unsupported action: {action}"},
                        success=False
                    )
                    
        except Exception as e:
            print(f"âŒ ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            await self.reply_to_message(
                message,
                result={"error": str(e)},
                success=False
            )
            
    async def _handle_sec_collection(self, message: A2AMessage):
        """SEC ê³µì‹œ ìˆ˜ì§‘ ìš”ì²­ ì²˜ë¦¬"""
        payload = message.body.get("payload", {})
        ticker = payload.get("ticker", "")
        
        print(f"ğŸ“„ SEC ê³µì‹œ ìˆ˜ì§‘ ì‹œì‘: {ticker}")
        
        try:
            # SEC EDGAR APIë¡œ ê³µì‹œ ìˆ˜ì§‘
            filings_data = await self._fetch_sec_filings(ticker)
            
            # ê²°ê³¼ í¬ë§·íŒ…
            result = {
                "data": filings_data,
                "count": len(filings_data),
                "source": "sec",
                "log_message": f"âœ… {ticker} ê³µì‹œ {len(filings_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ"
            }
            
            # ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ì´ë²¤íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            await self.broadcast_event(
                event_type="data_collected",
                event_data={
                    "source": "sec",
                    "ticker": ticker,
                    "count": len(filings_data)
                }
            )
            
            await self.reply_to_message(message, result=result, success=True)
            
        except Exception as e:
            print(f"âŒ SEC ê³µì‹œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            await self.reply_to_message(
                message,
                result={"error": str(e), "data": [], "count": 0},
                success=False
            )
            
    async def _extract_filing_content(self, filing_url: str, form_type: str) -> Dict[str, Any]:
        """ê³µì‹œ ë¬¸ì„œì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ ë° ë²ˆì—­"""
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.get(
                    filing_url,
                    headers={"User-Agent": self.user_agent}
                )
                
                if response.status_code != 200:
                    return {}
                    
                content = response.text
                
                # HTML ë¬¸ì„œì¸ ê²½ìš° BeautifulSoupìœ¼ë¡œ íŒŒì‹±
                if "<html" in content.lower():
                    soup = BeautifulSoup(content, 'html.parser')
                    text_content = soup.get_text()
                else:
                    text_content = content
                    
                # í¼ íƒ€ì…ë³„ í•µì‹¬ ì •ë³´ ì¶”ì¶œ
                extracted_info = {
                    "filing_url": filing_url,
                    "extraction_timestamp": datetime.now().isoformat()
                }
                
                if form_type == "10-K":
                    # ì—°ê°„ ë³´ê³ ì„œì—ì„œ í•µì‹¬ ì¬ë¬´ ì •ë³´ ì¶”ì¶œ
                    extracted_info.update(await self._extract_10k_info_enhanced(text_content))
                elif form_type == "10-Q":
                    # ë¶„ê¸° ë³´ê³ ì„œì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ
                    extracted_info.update(await self._extract_10q_info_enhanced(text_content))
                elif form_type == "8-K":
                    # ì„ì‹œ ë³´ê³ ì„œì—ì„œ ì£¼ìš” ì´ë²¤íŠ¸ ì¶”ì¶œ
                    extracted_info.update(await self._extract_8k_info_enhanced(text_content))
                elif form_type == "DEF 14A":
                    # ì£¼ì£¼ì´íšŒ ìœ„ì„ì¥ì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ
                    extracted_info.update(await self._extract_proxy_info_enhanced(text_content))
                    
                return extracted_info
                
        except Exception as e:
            print(f"âŒ ê³µì‹œ ë‚´ìš© ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {}
            
    async def _extract_10k_info_enhanced(self, text: str) -> Dict[str, Any]:
        """10-K ì—°ê°„ ë³´ê³ ì„œì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ë° ë²ˆì—­"""
        info = {
            "key_metrics": [],
            "key_metrics_translated": [],
            "risks": [],
            "risks_translated": [],
            "business_highlights": [],
            "business_highlights_translated": [],
            "financial_data": {},
            "md&a_summary": "",
            "md&a_summary_translated": ""
        }
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        text = text.replace('\n', ' ').replace('\t', ' ')
        text = ' '.join(text.split())  # ë‹¤ì¤‘ ê³µë°± ì œê±°
        
        # MD&A (Management Discussion and Analysis) ì„¹ì…˜ ì¶”ì¶œ
        mda_pattern = r"(?:management.?s discussion and analysis|md&a).*?(?=item|part|\Z)"
        mda_match = re.search(mda_pattern, text[:50000], re.IGNORECASE | re.DOTALL)
        if mda_match:
            mda_text = mda_match.group(0)[:2000]  # ì²« 2000ìë§Œ
            # MD&A ìš”ì•½
            summary_sentences = mda_text.split('.')[:5]  # ì²« 5ë¬¸ì¥
            info["md&a_summary"] = '. '.join(summary_sentences)
            info["md&a_summary_translated"] = await translate_text(info["md&a_summary"], "ko")
        
        # ê¸°ì¡´ ì¶”ì¶œ ë¡œì§ ê³„ì†...
        # 1. ë§¤ì¶œ ì •ë³´ ì¶”ì¶œ
        revenue_patterns = [
            r"(?:total\s+)?(?:net\s+)?revenue[s]?(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"(?:total\s+)?net\s+sales(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)"
        ]
        
        for pattern in revenue_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                value = match.group(1).replace(',', '')
                unit = "million" if "million" in match.group(0).lower() else "billion"
                multiplier = 1000000 if unit == "million" else 1000000000
                actual_value = float(value) * multiplier
                
                metric_en = f"Revenue: ${value} {unit}"
                metric_ko = f"ë§¤ì¶œ: ${value} {unit}"
                
                info["key_metrics"].append(metric_en)
                info["key_metrics_translated"].append(metric_ko)
                info["financial_data"]["revenue"] = actual_value
                break
            if info["financial_data"].get("revenue"):
                break
        
        # ë¦¬ìŠ¤í¬ ìš”ì¸ ì¶”ì¶œ (Risk Factors ì„¹ì…˜)
        risk_section_pattern = r"(?:risk factors).*?(?=item|part|\Z)"
        risk_match = re.search(risk_section_pattern, text[:100000], re.IGNORECASE | re.DOTALL)
        if risk_match:
            risk_text = risk_match.group(0)[:5000]
            # ì£¼ìš” ë¦¬ìŠ¤í¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            risk_keywords = [
                "competition", "regulatory", "economic conditions", "cybersecurity",
                "supply chain", "pandemic", "climate change", "litigation"
            ]
            for keyword in risk_keywords:
                if keyword in risk_text.lower():
                    risk_en = f"Risk: {keyword.title()}"
                    risk_ko = await translate_text(risk_en, "ko")
                    info["risks"].append(risk_en)
                    info["risks_translated"].append(risk_ko)
        
        return info
    
    def _extract_10k_info(self, text: str) -> Dict[str, Any]:
        """10-K ì—°ê°„ ë³´ê³ ì„œì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ"""
        info = {
            "key_metrics": [],
            "risks": [],
            "business_highlights": [],
            "financial_data": {}
        }
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        text = text.replace('\n', ' ').replace('\t', ' ')
        text = ' '.join(text.split())  # ë‹¤ì¤‘ ê³µë°± ì œê±°
        
        # 1. ë§¤ì¶œ ì •ë³´ ì¶”ì¶œ (ë” ì •êµí•œ íŒ¨í„´)
        revenue_patterns = [
            r"(?:total\s+)?(?:net\s+)?revenue[s]?(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"(?:total\s+)?net\s+sales(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"(?:total\s+)?revenue[s]?(?:\s+of)?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"revenue[s]?\s+(?:increased|decreased|was).*?\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)"
        ]
        
        for pattern in revenue_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                value = match.group(1).replace(',', '')
                unit = "million" if "million" in match.group(0).lower() else "billion"
                multiplier = 1000000 if unit == "million" else 1000000000
                actual_value = float(value) * multiplier
                info["key_metrics"].append(f"ë§¤ì¶œ: ${value} {unit}")
                info["financial_data"]["revenue"] = actual_value
                break
            if info["financial_data"].get("revenue"):
                break
                
        # 2. ìˆœì´ìµ ì •ë³´ ì¶”ì¶œ
        income_patterns = [
            r"net\s+income(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"net\s+earnings(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"net\s+(?:income|earnings)\s+of\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)"
        ]
        
        for pattern in income_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                value = match.group(1).replace(',', '')
                unit = "million" if "million" in match.group(0).lower() else "billion"
                multiplier = 1000000 if unit == "million" else 1000000000
                actual_value = float(value) * multiplier
                info["key_metrics"].append(f"ìˆœì´ìµ: ${value} {unit}")
                info["financial_data"]["net_income"] = actual_value
                break
            if info["financial_data"].get("net_income"):
                break
                
        # 3. ì˜ì—…ì´ìµ ì¶”ì¶œ
        operating_patterns = [
            r"operating\s+income(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"income\s+from\s+operations(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)"
        ]
        
        for pattern in operating_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                value = match.group(1).replace(',', '')
                unit = "million" if "million" in match.group(0).lower() else "billion"
                info["key_metrics"].append(f"ì˜ì—…ì´ìµ: ${value} {unit}")
                break
                
        # 4. ìì‚° ì •ë³´ ì¶”ì¶œ
        asset_patterns = [
            r"total\s+assets(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"assets\s+of\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)"
        ]
        
        for pattern in asset_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                value = match.group(1).replace(',', '')
                unit = "million" if "million" in match.group(0).lower() else "billion"
                info["key_metrics"].append(f"ì´ìì‚°: ${value} {unit}")
                break
                
        # 5. ì„±ì¥ë¥  ì¶”ì¶œ
        growth_patterns = [
            r"revenue[s]?\s+(?:increased|grew)(?:\s+by)?\s+([\d.]+)%",
            r"([\d.]+)%\s+(?:increase|growth)\s+in\s+revenue",
            r"revenue[s]?\s+(?:decreased|declined)(?:\s+by)?\s+([\d.]+)%"
        ]
        
        for pattern in growth_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                growth = match.group(1)
                if "decreased" in match.group(0).lower() or "declined" in match.group(0).lower():
                    growth = f"-{growth}"
                info["key_metrics"].append(f"ë§¤ì¶œ ì„±ì¥ë¥ : {growth}%")
                break
                
        # 6. ë¦¬ìŠ¤í¬ íŒ©í„° ì¶”ì¶œ (Risk Factors ì„¹ì…˜ì—ì„œ êµ¬ì²´ì ì¸ ë‚´ìš© ì¶”ì¶œ)
        risk_section = re.search(r"risk\s+factors(.*?)(?:item\s+\d|$)", text, re.IGNORECASE | re.DOTALL)
        if risk_section:
            risk_text = risk_section.group(1)[:2000]  # ì²˜ìŒ 2000ìë§Œ
            
            # ì£¼ìš” ë¦¬ìŠ¤í¬ í‚¤ì›Œë“œ ì°¾ê¸°
            risk_keywords = [
                "competition", "regulatory", "economic conditions", "supply chain",
                "cybersecurity", "pandemic", "climate change", "currency fluctuation",
                "intellectual property", "data privacy", "market volatility"
            ]
            
            found_risks = []
            for keyword in risk_keywords:
                if keyword in risk_text.lower():
                    korean_map = {
                        "competition": "ê²½ìŸ ì‹¬í™”",
                        "regulatory": "ê·œì œ ë¦¬ìŠ¤í¬",
                        "economic conditions": "ê²½ì œ ìƒí™©",
                        "supply chain": "ê³µê¸‰ë§ ë¦¬ìŠ¤í¬",
                        "cybersecurity": "ì‚¬ì´ë²„ë³´ì•ˆ",
                        "pandemic": "íŒ¬ë°ë¯¹ ë¦¬ìŠ¤í¬",
                        "climate change": "ê¸°í›„ë³€í™”",
                        "currency fluctuation": "í™˜ìœ¨ ë³€ë™",
                        "intellectual property": "ì§€ì ì¬ì‚°ê¶Œ",
                        "data privacy": "ë°ì´í„° í”„ë¼ì´ë²„ì‹œ",
                        "market volatility": "ì‹œì¥ ë³€ë™ì„±"
                    }
                    found_risks.append(korean_map.get(keyword, keyword))
            
            if found_risks:
                info["risks"] = found_risks[:5]  # ìƒìœ„ 5ê°œë§Œ
            else:
                info["risks"].append("ì¼ë°˜ì ì¸ ì‚¬ì—… ë¦¬ìŠ¤í¬")
                
        # 7. ì‚¬ì—… í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ
        highlight_keywords = [
            r"launched\s+new\s+product",
            r"acquired\s+(?:company|business)",
            r"expanded\s+(?:into|operations)",
            r"partnership\s+with",
            r"investment\s+in\s+(?:R&D|research)",
            r"market\s+share\s+(?:increased|grew)"
        ]
        
        for pattern in highlight_keywords:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                context = text[max(0, match.start()-50):min(len(text), match.end()+50)]
                info["business_highlights"].append(context.strip())
                
        return info
        
    async def _extract_10q_info_enhanced(self, text: str) -> Dict[str, Any]:
        """10-Q ë¶„ê¸° ë³´ê³ ì„œì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ë° ë²ˆì—­"""
        info = {
            "quarterly_metrics": [],
            "quarterly_metrics_translated": [],
            "segment_performance": [],
            "segment_performance_translated": [],
            "quarter_highlights": "",
            "quarter_highlights_translated": ""
        }
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        text = text.replace('\n', ' ').replace('\t', ' ')
        text = ' '.join(text.split())
        
        # ë¶„ê¸° ë§¤ì¶œ ì¶”ì¶œ
        quarterly_revenue = re.search(
            r"three\s+months.*?revenue.*?\$?([\d,]+(?:\.\d+)?)[\s]?(?:million|billion)",
            text, re.IGNORECASE
        )
        if quarterly_revenue:
            value = quarterly_revenue.group(1)
            metric_en = f"Quarterly Revenue: ${value}"
            metric_ko = f"ë¶„ê¸° ë§¤ì¶œ: ${value}"
            info["quarterly_metrics"].append(metric_en)
            info["quarterly_metrics_translated"].append(metric_ko)
            
        # ì „ë…„ ëŒ€ë¹„ ì„±ì¥ë¥ 
        yoy_pattern = re.search(
            r"compared\s+to.*?prior\s+year.*?([\d.]+)%",
            text, re.IGNORECASE
        )
        if yoy_pattern:
            growth = yoy_pattern.group(1)
            metric_en = f"YoY Growth: {growth}%"
            metric_ko = f"ì „ë…„ ëŒ€ë¹„ ì„±ì¥ë¥ : {growth}%"
            info["quarterly_metrics"].append(metric_en)
            info["quarterly_metrics_translated"].append(metric_ko)
        
        # ì„¸ê·¸ë¨¼íŠ¸ë³„ ì‹¤ì  ì¶”ì¶œ
        segment_pattern = r"segment.*?revenue.*?\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)"
        segment_matches = re.finditer(segment_pattern, text[:5000], re.IGNORECASE)
        for match in segment_matches[:3]:  # ìµœëŒ€ 3ê°œ
            segment_info = match.group(0)
            translated = await translate_text(segment_info, "ko")
            info["segment_performance"].append(segment_info)
            info["segment_performance_translated"].append(translated)
        
        # ë¶„ê¸° í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ
        highlight_section = re.search(
            r"(?:highlights|overview).*?(?=item|part|financial|$)",
            text[:3000], re.IGNORECASE | re.DOTALL
        )
        if highlight_section:
            highlights = highlight_section.group(0)[:500]
            info["quarter_highlights"] = highlights
            info["quarter_highlights_translated"] = await translate_text(highlights, "ko")
        
        return info
        
    def _extract_10q_info(self, text: str) -> Dict[str, Any]:
        """10-Q ë¶„ê¸° ë³´ê³ ì„œì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ"""
        info = {
            "quarterly_metrics": [],
            "segment_performance": []
        }
        
        # ë¶„ê¸° ë§¤ì¶œ ì¶”ì¶œ
        quarterly_revenue = re.search(
            r"three\s+months.*?revenue.*?\$?([\d,]+(?:\.\d+)?)[\s]?(?:million|billion)",
            text, re.IGNORECASE
        )
        if quarterly_revenue:
            info["quarterly_metrics"].append(f"ë¶„ê¸° ë§¤ì¶œ: ${quarterly_revenue.group(1)}")
            
        # ì „ë…„ ëŒ€ë¹„ ì„±ì¥ë¥ 
        growth_pattern = re.search(
            r"(?:increased?|decreased?|grew|declined?).*?([\d]+(?:\.\d+)?)\s*%",
            text, re.IGNORECASE
        )
        if growth_pattern:
            info["quarterly_metrics"].append(f"ì„±ì¥ë¥ : {growth_pattern.group(1)}%")
            
        return info
        
    async def _extract_8k_info_enhanced(self, text: str) -> Dict[str, Any]:
        """8-K ì„ì‹œ ë³´ê³ ì„œì—ì„œ ìƒì„¸ ì´ë²¤íŠ¸ ì •ë³´ ì¶”ì¶œ ë° ë²ˆì—­"""
        info = {
            "events": [],
            "events_translated": [],
            "event_details": [],
            "event_details_translated": [],
            "material_changes": "",
            "material_changes_translated": ""
        }
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        text = text.replace('\n', ' ').replace('\t', ' ')
        text = ' '.join(text.split())
        
        # Itemë³„ ì¤‘ìš” ì´ë²¤íŠ¸ ë§¤í•‘
        item_patterns = {
            "Item 1.01": "ì¤‘ìš” ê³„ì•½ ì²´ê²°",
            "Item 2.01": "ìì‚° ì¸ìˆ˜ ì™„ë£Œ",
            "Item 2.02": "ìš´ì˜ ê²°ê³¼ ë° ì¬ë¬´ ìƒíƒœ",
            "Item 2.03": "ì¤‘ìš” ì˜ë¬´ ë°œìƒ",
            "Item 2.05": "ì‚¬ì—… ì¤‘ë‹¨ ë¹„ìš©",
            "Item 3.01": "íŒŒì‚° ë˜ëŠ” ë²•ì •ê´€ë¦¬",
            "Item 5.02": "ì„ì› ë³€ê²½",
            "Item 5.03": "ì •ê´€ ë˜ëŠ” ê·œì • ë³€ê²½",
            "Item 7.01": "ê·œì œ ê³µì‹œ",
            "Item 8.01": "ê¸°íƒ€ ì¤‘ìš” ì‚¬í•­"
        }
        
        # Itemë³„ ì´ë²¤íŠ¸ ì¶”ì¶œ
        for item_code, item_desc in item_patterns.items():
            pattern = f"{item_code}.*?(?=Item|$)"
            match = re.search(pattern, text[:10000], re.IGNORECASE)
            if match:
                event_text = match.group(0)[:500]
                event_en = f"{item_code}: {event_text[:200]}..."
                event_ko = f"{item_code}: {item_desc}"
                
                info["events"].append(event_en)
                info["events_translated"].append(event_ko)
                
                # ìƒì„¸ ë‚´ìš© ì¶”ì¶œ
                detail_text = event_text[:300]
                detail_translated = await translate_text(detail_text, "ko")
                info["event_details"].append(detail_text)
                info["event_details_translated"].append(detail_translated)
        
        # ì¤‘ìš” ë³€ê²½ì‚¬í•­ ìš”ì•½
        material_section = re.search(
            r"(?:material|significant).*?(?:change|development|event).*?(?=\.|$)",
            text[:2000], re.IGNORECASE
        )
        if material_section:
            material_text = material_section.group(0)
            info["material_changes"] = material_text
            info["material_changes_translated"] = await translate_text(material_text, "ko")
        
        return info
    
    def _extract_8k_info(self, text: str) -> Dict[str, Any]:
        """8-K ì„ì‹œ ë³´ê³ ì„œì—ì„œ ì£¼ìš” ì´ë²¤íŠ¸ ì¶”ì¶œ"""
        info = {
            "events": [],
            "material_changes": []
        }
        
        # ì£¼ìš” ì´ë²¤íŠ¸ í‚¤ì›Œë“œ
        event_keywords = {
            "acquisition": "ì¸ìˆ˜í•©ë³‘",
            "merger": "í•©ë³‘",
            "resignation": "ê²½ì˜ì§„ ì‚¬ì„",
            "appointment": "ì‹ ê·œ ì„ëª…",
            "dividend": "ë°°ë‹¹ ë°œí‘œ",
            "buyback": "ìì‚¬ì£¼ ë§¤ì…",
            "restructuring": "êµ¬ì¡°ì¡°ì •",
            "litigation": "ì†Œì†¡",
            "partnership": "íŒŒíŠ¸ë„ˆì‹­",
            "product launch": "ì‹ ì œí’ˆ ì¶œì‹œ"
        }
        
        for eng, kor in event_keywords.items():
            if eng in text.lower():
                info["events"].append(kor)
                
        return info
        
    async def _extract_proxy_info_enhanced(self, text: str) -> Dict[str, Any]:
        """DEF 14A ì£¼ì£¼ì´íšŒ ìœ„ì„ì¥ì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ë° ë²ˆì—­"""
        info = {
            "executive_compensation": [],
            "executive_compensation_translated": [],
            "proposals": [],
            "proposals_translated": [],
            "board_changes": [],
            "board_changes_translated": [],
            "governance_highlights": "",
            "governance_highlights_translated": ""
        }
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        text = text.replace('\n', ' ').replace('\t', ' ')
        text = ' '.join(text.split())
        
        # ì„ì› ë³´ìˆ˜ ì •ë³´ ì¶”ì¶œ
        comp_patterns = [
            r"(?:CEO|chief executive).*?compensation.*?\$?([\d,]+(?:\.\d+)?)\s*(?:million|thousand)?",
            r"named executive officers.*?total.*?\$?([\d,]+(?:\.\d+)?)\s*(?:million|thousand)?",
            r"total compensation.*?\$?([\d,]+(?:\.\d+)?)\s*(?:million|thousand)?"
        ]
        
        for pattern in comp_patterns[:3]:  # ìµœëŒ€ 3ê°œ
            match = re.search(pattern, text[:10000], re.IGNORECASE)
            if match:
                comp_info = match.group(0)
                comp_translated = await translate_text(comp_info, "ko")
                info["executive_compensation"].append(comp_info)
                info["executive_compensation_translated"].append(comp_translated)
        
        # ì£¼ì£¼ ì œì•ˆ ì¶”ì¶œ
        proposal_pattern = r"proposal\s*\d+.*?(?=proposal|$)"
        proposal_matches = re.finditer(proposal_pattern, text[:20000], re.IGNORECASE)
        
        for i, match in enumerate(proposal_matches):
            if i >= 5:  # ìµœëŒ€ 5ê°œ ì œì•ˆ
                break
            proposal_text = match.group(0)[:300]
            proposal_translated = await translate_text(proposal_text, "ko")
            info["proposals"].append(proposal_text)
            info["proposals_translated"].append(proposal_translated)
        
        # ì´ì‚¬íšŒ ë³€ê²½ì‚¬í•­
        board_patterns = [
            r"(?:elect|nominate|appoint).*?director",
            r"board.*?(?:resignation|retirement)",
            r"new.*?board member"
        ]
        
        for pattern in board_patterns:
            match = re.search(pattern, text[:10000], re.IGNORECASE)
            if match:
                board_info = text[max(0, match.start()-100):match.end()+100]
                board_translated = await translate_text(board_info, "ko")
                info["board_changes"].append(board_info)
                info["board_changes_translated"].append(board_translated)
        
        # ê±°ë²„ë„ŒìŠ¤ í•˜ì´ë¼ì´íŠ¸
        governance_section = re.search(
            r"(?:corporate governance|governance highlights).*?(?=item|proposal|$)",
            text[:5000], re.IGNORECASE | re.DOTALL
        )
        if governance_section:
            governance_text = governance_section.group(0)[:500]
            info["governance_highlights"] = governance_text
            info["governance_highlights_translated"] = await translate_text(governance_text, "ko")
        
        return info
    
    def _extract_proxy_info(self, text: str) -> Dict[str, Any]:
        """DEF 14A ì£¼ì£¼ì´íšŒ ìœ„ì„ì¥ì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ"""
        info = {
            "executive_compensation": [],
            "proposals": []
        }
        
        # ì„ì› ë³´ìˆ˜ ì •ë³´
        comp_pattern = re.search(
            r"total\s+compensation.*?\$?([\d,]+(?:\.\d+)?)[\s]?(?:million)?",
            text, re.IGNORECASE
        )
        if comp_pattern:
            info["executive_compensation"].append(f"ì„ì› ì´ ë³´ìˆ˜: ${comp_pattern.group(1)}")
            
        # ì£¼ì£¼ ì œì•ˆ ì‚¬í•­
        if "proposal" in text.lower():
            info["proposals"].append("ì£¼ì£¼ ì œì•ˆ ì‚¬í•­ í¬í•¨")
            
        return info
    
    async def _get_cik_for_ticker(self, ticker: str) -> str:
        """í‹°ì»¤ì—ì„œ CIK(Central Index Key) ì¡°íšŒ"""
        # ìºì‹œ í™•ì¸
        if ticker.upper() in self.cik_cache:
            return self.cik_cache[ticker.upper()]
            
        try:
            # SECì˜ ê³µì‹ í‹°ì»¤-CIK ë§¤í•‘ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            url = "https://www.sec.gov/files/company_tickers.json"
            headers = {"User-Agent": self.user_agent}
            
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.get(url, headers=headers)
                
                if response.status_code == 200:
                    tickers_data = response.json()
                    
                    # ëª¨ë“  íšŒì‚¬ ì •ë³´ë¥¼ ìºì‹œì— ì €ì¥
                    for company_data in tickers_data.values():
                        company_ticker = company_data.get('ticker', '').upper()
                        cik = str(company_data.get('cik_str', '')).zfill(10)
                        if company_ticker:
                            self.cik_cache[company_ticker] = cik
                    
                    # ìš”ì²­ëœ í‹°ì»¤ì˜ CIK ë°˜í™˜
                    result = self.cik_cache.get(ticker.upper(), None)
                    if not result:
                        raise DataNotFoundError("CIK", ticker)
                    return result
                elif response.status_code == 429:
                    raise APIRateLimitError("SEC", 60)
                else:
                    logger.error(f"âŒ SEC í‹°ì»¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {response.status_code}")
                    return None
                    
        except Exception as e:
            print(f"âŒ CIK ì¡°íšŒ ì˜¤ë¥˜: {e}")
            # í´ë°±: ê¸°ë³¸ CIK ë§¤í•‘ ì‚¬ìš©
            fallback_map = {
                "AAPL": "0000320193",
                "TSLA": "0001318605",
                "NVDA": "0001045810",
                "GOOGL": "0001652044",
                "MSFT": "0000789019",
                "AMZN": "0001018724",
                "META": "0001326801",
                "PLTR": "0001321655"
            }
            return fallback_map.get(ticker.upper())
    
    async def _fetch_sec_filings(self, ticker: str) -> List[Dict]:
        """SEC EDGAR APIë¡œ ê³µì‹œ ê°€ì ¸ì˜¤ê¸°"""
        # ë”ë¯¸ ë°ì´í„° ì‚¬ìš© ëª¨ë“œì¸ ê²½ìš°
        if self.use_mock_data:
            logger.info(f"ğŸ­ ë”ë¯¸ ë°ì´í„° ëª¨ë“œ í™œì„±í™” - ëª¨ì˜ SEC ê³µì‹œ ë°˜í™˜")
            return self._get_mock_filings(ticker)
            
        try:
            # ë™ì  CIK ì¡°íšŒ
            cik = await self._get_cik_for_ticker(ticker)
            if not cik:
                logger.warning(f"âš ï¸ {ticker}ì˜ CIKë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return []  # ë¹ˆ ë°ì´í„° ë°˜í™˜
                
            # SEC EDGAR API í˜¸ì¶œ
            url = f"https://data.sec.gov/submissions/CIK{cik}.json"
            headers = {
                "User-Agent": self.user_agent,
                "Accept-Encoding": "gzip, deflate"
            }
            
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.get(url, headers=headers)
                
                if response.status_code == 200:
                    data = response.json()
                    recent_filings = data.get("filings", {}).get("recent", {})
                    
                    # ìµœê·¼ ê³µì‹œ í¬ë§·íŒ…
                    formatted_filings = []
                    forms = recent_filings.get("form", [])[:self.max_filings]
                    dates = recent_filings.get("filingDate", [])[:self.max_filings]
                    accessions = recent_filings.get("accessionNumber", [])[:self.max_filings]
                    
                    # ëª¨ë“  ë°°ì—´ì˜ ìµœì†Œ ê¸¸ì´ í™•ì¸
                    max_items = min(len(forms), len(dates), len(accessions), self.max_filings)
                    
                    for i in range(max_items):
                        # ê° ë°°ì—´ ìš”ì†Œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                        form_type = forms[i] if i < len(forms) else "Unknown"
                        filing_date = dates[i] if i < len(dates) else ""
                        accession_number = accessions[i] if i < len(accessions) else ""
                        
                        if not accession_number:
                            continue
                            
                        filing_url = f"https://www.sec.gov/Archives/edgar/data/{cik.lstrip('0')}/{accession_number.replace('-', '')}/{accession_number}.txt"
                        
                        # í¼ íƒ€ì…ë³„ ì„¤ëª… ì¶”ê°€
                        form_descriptions = {
                            "10-K": "ì—°ê°„ ë³´ê³ ì„œ - íšŒì‚¬ì˜ ì—°ê°„ ì‹¤ì  ë° ì¬ë¬´ìƒíƒœ",
                            "10-Q": "ë¶„ê¸° ë³´ê³ ì„œ - ë¶„ê¸°ë³„ ì‹¤ì  ë° ê²½ì˜ í˜„í™©",
                            "8-K": "ì„ì‹œ ë³´ê³ ì„œ - ì£¼ìš” ì´ë²¤íŠ¸ ë° ê²½ì˜ìƒ ì¤‘ìš” ë³€ê²½ì‚¬í•­",
                            "4": "ë‚´ë¶€ì ê±°ë˜ - ì„ì›ì§„ì˜ ì£¼ì‹ ë§¤ë§¤ ë‚´ì—­",
                            "DEF 14A": "ì£¼ì£¼ì´íšŒ ìœ„ì„ì¥ - ì£¼ì£¼ì´íšŒ ì•ˆê±´ ë° ì„ì› ë³´ìˆ˜",
                            "144": "ì œí•œ ì£¼ì‹ ë§¤ë„ ì‹ ê³  - ë‚´ë¶€ìì˜ ì£¼ì‹ ë§¤ë„ ê³„íš",
                            "S-8": "ì§ì› ì£¼ì‹ ì˜µì…˜ - ì§ì› ëŒ€ìƒ ì£¼ì‹ ë°œí–‰ ê³„íš",
                            "S-3": "ìœ ê°€ì¦ê¶Œ ì‹ ê³ ì„œ - ì‹ ê·œ ì¦ê¶Œ ë°œí–‰ ê³„íš"
                        }
                        
                        form_desc = form_descriptions.get(form_type, "ê¸°íƒ€ ê³µì‹œ")
                        
                        # SEC ê³µì‹œ ì œëª©ê³¼ ìš”ì•½ ìƒì„±
                        title = f"{ticker} {form_type} ê³µì‹œ ({filing_date})"
                        content = f"{form_desc}. ì´ ê³µì‹œëŠ” {ticker}ì˜ {form_type} ì–‘ì‹ìœ¼ë¡œ ì œì¶œëœ ê³µì‹ ë¬¸ì„œì…ë‹ˆë‹¤."
                        
                        # ê³µì‹œ ë¬¸ì„œì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ ì‹œë„
                        extracted_info = await self._extract_filing_content(filing_url, form_type)
                        
                        # ì¶”ì¶œëœ ì •ë³´ë¥¼ contentì— ì¶”ê°€ (ë²ˆì—­ëœ ë²„ì „ ìš°ì„  ì‚¬ìš©)
                        if extracted_info:
                            if extracted_info.get("key_metrics_translated"):
                                content += f" ì£¼ìš” ì§€í‘œ: {', '.join(extracted_info['key_metrics_translated'])}"
                            elif extracted_info.get("key_metrics"):
                                content += f" ì£¼ìš” ì§€í‘œ: {', '.join(extracted_info['key_metrics'])}"
                                
                            if extracted_info.get("quarterly_metrics"):
                                content += f" ë¶„ê¸° ì‹¤ì : {', '.join(extracted_info['quarterly_metrics'])}"
                                
                            if extracted_info.get("events"):
                                content += f" ì£¼ìš” ì´ë²¤íŠ¸: {', '.join(extracted_info['events'])}"
                                
                            if extracted_info.get("risks_translated"):
                                content += f" ë¦¬ìŠ¤í¬ ìš”ì¸: {', '.join(extracted_info['risks_translated'])}"
                            elif extracted_info.get("risks"):
                                content += f" ë¦¬ìŠ¤í¬ ìš”ì¸: {', '.join(extracted_info['risks'])}"
                                
                            if extracted_info.get("md&a_summary_translated"):
                                content += f" ê²½ì˜ì§„ ë¶„ì„: {extracted_info['md&a_summary_translated'][:200]}..."
                        
                        formatted_filings.append({
                            "form_type": form_type,
                            "title": title,
                            "content": content,
                            "description": form_desc,
                            "filing_date": filing_date,
                            "url": filing_url,
                            "source": "sec",
                            "sentiment": None,  # ë‚˜ì¤‘ì— ê°ì •ë¶„ì„ì—ì„œ ì±„ì›€
                            "extracted_info": extracted_info,  # ì¶”ì¶œëœ ìƒì„¸ ì •ë³´
                            "timestamp": datetime.now().isoformat(),  # ìˆ˜ì§‘ íƒ€ì„ìŠ¤íƒ¬í”„
                            "log_message": f"ğŸ“„ ê³µì‹œ: {form_type} - {filing_date}"
                        })
                        
                    return formatted_filings
                elif response.status_code == 429:
                    raise APIRateLimitError("SEC", 60)
                else:
                    logger.error(f"âŒ SEC API ì˜¤ë¥˜: {response.status_code}")
                    return []  # ë¹ˆ ë°ì´í„° ë°˜í™˜
                    
        except (APIRateLimitError, DataNotFoundError):
            raise  # ì»¤ìŠ¤í…€ ì—ëŸ¬ëŠ” ë‹¤ì‹œ ë°œìƒì‹œí‚´
        except httpx.TimeoutException:
            raise APITimeoutError("SEC", self.timeout)
        except Exception as e:
            logger.error(f"âŒ SEC API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return []  # ë¹ˆ ë°ì´í„° ë°˜í™˜
            
    def _get_mock_filings(self, ticker: str) -> List[Dict]:
        """ëª¨ì˜ ê³µì‹œ ë°ì´í„° ìƒì„± - í‹°ì»¤ë³„ë¡œ ë‹¤ë¥¸ ë‚´ìš©"""
        today = datetime.now()
        
        # í‹°ì»¤ë³„ íŠ¹í™”ëœ ê³µì‹œ ë°ì´í„°
        ticker_specific_filings = {
            "AAPL": [
                {
                    "form_type": "10-K",
                    "title": "Annual Report - 2024 íšŒê³„ì—°ë„ ë§¤ì¶œ 4,000ì–µ ë‹¬ëŸ¬ ëŒíŒŒ",
                    "filing_date": (today - timedelta(days=30)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/10K-2024",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ì• í”Œ ì—°ê°„ ë§¤ì¶œ ì‚¬ìƒ ìµœëŒ€ ê¸°ë¡. ì„œë¹„ìŠ¤ ë¶€ë¬¸ ì„±ì¥ì´ ê²¬ì¸",
                    "log_message": "ğŸ“„ ê³µì‹œ: 10-K - ì—°ê°„ ë§¤ì¶œ ìµœëŒ€ ê¸°ë¡"
                },
                {
                    "form_type": "10-Q",
                    "title": "Quarterly Report - Q3 2024 ì•„ì´í° íŒë§¤ ë‘”í™”",
                    "filing_date": (today - timedelta(days=10)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/10Q-Q3-2024",
                    "source": "sec",
                    "sentiment": None,
                    "content": "3ë¶„ê¸° ì•„ì´í° íŒë§¤ëŸ‰ ì „ë…„ ëŒ€ë¹„ 5% ê°ì†Œ. ì¤‘êµ­ ì‹œì¥ ë¶€ì§„",
                    "log_message": "ğŸ“„ ê³µì‹œ: 10-Q - ì•„ì´í° íŒë§¤ ë‘”í™”"
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - ìì‚¬ì£¼ 900ì–µ ë‹¬ëŸ¬ ë§¤ì… ë°œí‘œ",
                    "filing_date": (today - timedelta(days=2)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-buyback",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ì• í”Œ ì´ì‚¬íšŒ, 900ì–µ ë‹¬ëŸ¬ ê·œëª¨ ìì‚¬ì£¼ ë§¤ì… í”„ë¡œê·¸ë¨ ìŠ¹ì¸",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - ëŒ€ê·œëª¨ ìì‚¬ì£¼ ë§¤ì…"
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - AI ì—°êµ¬ê°œë°œ íˆ¬ì í™•ëŒ€",
                    "filing_date": (today - timedelta(days=5)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-ai",
                    "source": "sec",
                    "sentiment": None,
                    "content": "AI ë° ë¨¸ì‹ ëŸ¬ë‹ ì—°êµ¬ê°œë°œì— 50ì–µ ë‹¬ëŸ¬ ì¶”ê°€ íˆ¬ì ê³„íš",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - AI R&D íˆ¬ì"
                },
                {
                    "form_type": "DEF 14A",
                    "title": "Proxy Statement - ì„ì› ë³´ìˆ˜ 15% ì¸ìƒ",
                    "filing_date": (today - timedelta(days=15)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/DEF14A",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ì£¼ì£¼ì´íšŒ ì•ˆê±´: CEO ë° ì£¼ìš” ì„ì› ë³´ìˆ˜ ì¸ìƒì•ˆ",
                    "log_message": "ğŸ“„ ê³µì‹œ: DEF 14A - ì„ì› ë³´ìˆ˜"
                }
            ],
            "TSLA": [
                {
                    "form_type": "10-K",
                    "title": "Annual Report - 2024 ì°¨ëŸ‰ ì¸ë„ëŸ‰ 180ë§ŒëŒ€ ë‹¬ì„±",
                    "filing_date": (today - timedelta(days=30)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/10K-2024",
                    "source": "sec",
                    "sentiment": None,
                    "content": "í…ŒìŠ¬ë¼ ì—°ê°„ ì°¨ëŸ‰ ì¸ë„ëŸ‰ 180ë§ŒëŒ€ë¡œ ì „ë…„ ëŒ€ë¹„ 35% ì„±ì¥",
                    "log_message": "ğŸ“„ ê³µì‹œ: 10-K - ì°¨ëŸ‰ ì¸ë„ëŸ‰ ì‹ ê¸°ë¡"
                },
                {
                    "form_type": "10-Q",
                    "title": "Quarterly Report - Q3 2024 ì˜ì—…ì´ìµë¥  9.6%",
                    "filing_date": (today - timedelta(days=10)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/10Q-Q3-2024",
                    "source": "sec",
                    "sentiment": None,
                    "content": "3ë¶„ê¸° ì˜ì—…ì´ìµë¥  ê°œì„ . ì œì¡° íš¨ìœ¨ì„± í–¥ìƒ íš¨ê³¼",
                    "log_message": "ğŸ“„ ê³µì‹œ: 10-Q - ìˆ˜ìµì„± ê°œì„ "
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - ë©•ì‹œì½” ê¸°ê°€íŒ©í† ë¦¬ ê±´ì„¤ ì°©ìˆ˜",
                    "filing_date": (today - timedelta(days=2)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-mexico",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ë©•ì‹œì½” ê¸°ê°€íŒ©í† ë¦¬ ê±´ì„¤ ê³µì‹ ì°©ìˆ˜. 100ì–µ ë‹¬ëŸ¬ íˆ¬ì",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - ë©•ì‹œì½” ê³µì¥"
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - FSD v12 ë² íƒ€ ì¶œì‹œ",
                    "filing_date": (today - timedelta(days=7)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-fsd",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ì™„ì „ììœ¨ì£¼í–‰(FSD) v12 ë² íƒ€ ë²„ì „ ë¶ë¯¸ ì‹œì¥ ì¶œì‹œ",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - FSD ì—…ë°ì´íŠ¸"
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - ì—ë„ˆì§€ ì‚¬ì—…ë¶€ ë¶„ì‚¬ ê²€í† ",
                    "filing_date": (today - timedelta(days=20)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-energy",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ì—ë„ˆì§€ ì €ì¥ì¥ì¹˜ ì‚¬ì—…ë¶€ ë¶„ì‚¬ ê°€ëŠ¥ì„± ê²€í†  ì¤‘",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - ì‚¬ì—…ë¶€ ë¶„ì‚¬"
                }
            ],
            "NVDA": [
                {
                    "form_type": "10-K",
                    "title": "Annual Report - 2024 ë°ì´í„°ì„¼í„° ë§¤ì¶œ 600% ì„±ì¥",
                    "filing_date": (today - timedelta(days=30)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/10K-2024",
                    "source": "sec",
                    "sentiment": None,
                    "content": "AI ë¶ìœ¼ë¡œ ë°ì´í„°ì„¼í„° ë¶€ë¬¸ ë§¤ì¶œ ì „ë…„ ëŒ€ë¹„ 600% ê¸‰ì¦",
                    "log_message": "ğŸ“„ ê³µì‹œ: 10-K - ë°ì´í„°ì„¼í„° ë§¤ì¶œ ê¸‰ì¦"
                },
                {
                    "form_type": "10-Q",
                    "title": "Quarterly Report - Q3 2024 ë§¤ì¶œ 181ì–µ ë‹¬ëŸ¬",
                    "filing_date": (today - timedelta(days=10)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/10Q-Q3-2024",
                    "source": "sec",
                    "sentiment": None,
                    "content": "3ë¶„ê¸° ë§¤ì¶œ ì‹œì¥ ì˜ˆìƒì¹˜ 20% ìƒíšŒ. H100 ìˆ˜ìš” ì§€ì†",
                    "log_message": "ğŸ“„ ê³µì‹œ: 10-Q - ì‹¤ì  ì„œí”„ë¼ì´ì¦ˆ"
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - H200 ì¹© ëŒ€ëŸ‰ ìƒì‚° ì‹œì‘",
                    "filing_date": (today - timedelta(days=2)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-h200",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ì°¨ì„¸ëŒ€ AI ì¹© H200 ëŒ€ëŸ‰ ìƒì‚° ëŒì…. ì„±ëŠ¥ 70% í–¥ìƒ",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - H200 ìƒì‚°"
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - ì¤‘êµ­ ìˆ˜ì¶œ ì œí•œ ëŒ€ì‘ ê³„íš",
                    "filing_date": (today - timedelta(days=8)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-china",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ì¤‘êµ­ ì‹œì¥ìš© ê·œì œ ì¤€ìˆ˜ ì¹© ê°œë°œ. ì„±ëŠ¥ ì œí•œ ë²„ì „ ì¶œì‹œ",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - ì¤‘êµ­ ëŒ€ì‘"
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - ARM ì¸ìˆ˜ ì² íšŒ í›„ íŒŒíŠ¸ë„ˆì‹­",
                    "filing_date": (today - timedelta(days=25)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-arm",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ARMê³¼ 20ë…„ ë¼ì´ì„ ìŠ¤ ê³„ì•½ ì²´ê²°. CPU ì„¤ê³„ í˜‘ë ¥ ê°•í™”",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - ARM íŒŒíŠ¸ë„ˆì‹­"
                }
            ]
        }
        
        # ê¸°ë³¸ ê³µì‹œ í…œí”Œë¦¿
        default_filings = [
            {
                "form_type": "10-K",
                "title": "Annual Report",
                "filing_date": (today - timedelta(days=30)).strftime("%Y-%m-%d"),
                "url": f"https://sec.gov/example/{ticker}/10K",
                "source": "sec",
                "sentiment": None,
                "content": "ì—°ê°„ ë³´ê³ ì„œ",
                "log_message": "ğŸ“„ ê³µì‹œ: 10-K - Annual Report"
            },
            {
                "form_type": "10-Q",
                "title": "Quarterly Report",
                "filing_date": (today - timedelta(days=10)).strftime("%Y-%m-%d"),
                "url": f"https://sec.gov/example/{ticker}/10Q",
                "source": "sec",
                "sentiment": None,
                "content": "ë¶„ê¸° ë³´ê³ ì„œ",
                "log_message": "ğŸ“„ ê³µì‹œ: 10-Q - Quarterly Report"
            },
            {
                "form_type": "8-K",
                "title": "Current Report",
                "filing_date": (today - timedelta(days=2)).strftime("%Y-%m-%d"),
                "url": f"https://sec.gov/example/{ticker}/8K",
                "source": "sec",
                "sentiment": None,
                "content": "ì„ì‹œ ë³´ê³ ì„œ",
                "log_message": "ğŸ“„ ê³µì‹œ: 8-K - Current Report"
            }
        ]
        
        # í‹°ì»¤ì— ë§ëŠ” ê³µì‹œ ì„ íƒ
        filings_template = ticker_specific_filings.get(ticker, default_filings)
        
        return filings_template[:self.max_filings]
    
    def _setup_http_endpoints(self):
        """HTTP ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •"""
        @self.app.post("/collect_sec_data", dependencies=[Depends(verify_api_key)])
        async def collect_sec_data(request: SECRequest):
            """HTTPë¥¼ í†µí•œ SEC ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘"""
            try:
                print(f"ğŸ“„ HTTP ìš”ì²­ìœ¼ë¡œ SEC ê³µì‹œ ìˆ˜ì§‘: {request.ticker}")
                
                # SEC ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘
                filings_data = await self._fetch_sec_filings(request.ticker)
                
                result = {
                    "data": filings_data,
                    "count": len(filings_data),
                    "source": "sec",
                    "log_message": f"âœ… {request.ticker} ê³µì‹œ {len(filings_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ"
                }
                
                # ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ì´ë²¤íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸
                await self.broadcast_event(
                    event_type="data_collected",
                    event_data={
                        "source": "sec",
                        "ticker": request.ticker,
                        "count": len(filings_data)
                    }
                )
                
                return result
                
            except Exception as e:
                print(f"âŒ HTTP SEC ê³µì‹œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
                return {
                    "error": str(e),
                    "data": [],
                    "count": 0,
                    "source": "sec"
                }


# ëª¨ë“ˆ ë ˆë²¨ì—ì„œ ì—ì´ì „íŠ¸ì™€ app ìƒì„±
agent = SECAgentV2()
app = agent.app

@app.on_event("startup")
async def startup():
    await agent.start()

@app.on_event("shutdown")
async def shutdown():
    await agent.stop()

# ë…ë¦½ ì‹¤í–‰ìš©
if __name__ == "__main__":
    agent.run()