"""
SEC Agent V2 - ìˆœìˆ˜ A2A êµ¬í˜„

SEC ê³µì‹œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ë…ë¦½ì ì¸ V2 ì—ì´ì „íŠ¸
V1 ì˜ì¡´ì„± ì—†ì´ ì§ì ‘ SEC EDGAR API í˜¸ì¶œ
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import httpx
import asyncio
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from dotenv import load_dotenv
import re
from bs4 import BeautifulSoup
import json
import pandas as pd
from io import StringIO

from a2a_core.base.base_agent import BaseAgent
from a2a_core.protocols.message import A2AMessage, MessageType
from pydantic import BaseModel
from fastapi import Depends

# ì„¤ì • ê´€ë¦¬ì ë° ì»¤ìŠ¤í…€ ì—ëŸ¬ ì„í¬íŠ¸
from utils.config_manager import config
from utils.errors import APIRateLimitError, APITimeoutError, DataNotFoundError
from utils.auth import verify_api_key
from utils.translation_manager import translation_manager, translate_text

load_dotenv(override=True)

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class SECRequest(BaseModel):
    ticker: str


class SECAgentV2(BaseAgent):
    """SEC ê³µì‹œ ìˆ˜ì§‘ V2 ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        # ì„¤ì •ì—ì„œ ì—ì´ì „íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        agent_config = config.get_agent_config("sec")
        
        super().__init__(
            name=agent_config.get("name", "SEC Agent V2"),
            description="SEC ê³µì‹œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” A2A ì—ì´ì „íŠ¸",
            port=agent_config.get("port", 8210),
            registry_url="http://localhost:8001"
        )
        
        # API ì„¤ì •
        self.user_agent = config.get_env("SEC_API_USER_AGENT", "A2A-Agent/1.0")
        self.max_filings = int(config.get_env("MAX_SEC_FILINGS", "20"))
        
        # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        self.timeout = agent_config.get("timeout", 60)
        
        # ë”ë¯¸ ë°ì´í„° ì‚¬ìš© ì—¬ë¶€
        self.use_mock_data = config.is_mock_data_enabled()
        
        # ìºì‹œ ì„¤ì •
        self.cik_cache = {}  # CIK ë§¤í•‘ ìºì‹œ
        self.filing_cache = {}  # ê³µì‹œ ë¹„êµë¥¼ ìœ„í•œ ìºì‹œ
        
        # HTTP ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
        self._setup_http_endpoints()
        
    async def on_start(self):
        """ì—ì´ì „íŠ¸ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
        # ëŠ¥ë ¥ ë“±ë¡
        await self.register_capability({
            "name": "sec_data_collection",
            "version": "2.0",
            "description": "SEC ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘",
            "input_schema": {
                "type": "object",
                "properties": {
                    "ticker": {"type": "string", "description": "ì£¼ì‹ í‹°ì»¤"}
                },
                "required": ["ticker"]
            },
            "output_schema": {
                "type": "object",
                "properties": {
                    "data": {"type": "array"},
                    "count": {"type": "integer"},
                    "source": {"type": "string"}
                }
            }
        })
        
        print("âœ… SEC Agent V2 ì´ˆê¸°í™” ì™„ë£Œ")
        
    async def on_stop(self):
        """ì—ì´ì „íŠ¸ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
        print("ğŸ›‘ SEC Agent V2 ì¢…ë£Œ ì¤‘...")
        
    async def handle_message(self, message: A2AMessage):
        """ë©”ì‹œì§€ ì²˜ë¦¬"""
        try:
            if message.header.message_type == MessageType.REQUEST:
                action = message.body.get("action")
                
                if action == "sec_data_collection" or action == "collect_data":
                    await self._handle_sec_collection(message)
                else:
                    await self.reply_to_message(
                        message,
                        result={"error": f"Unsupported action: {action}"},
                        success=False
                    )
                    
        except Exception as e:
            print(f"âŒ ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            await self.reply_to_message(
                message,
                result={"error": str(e)},
                success=False
            )
            
    async def _handle_sec_collection(self, message: A2AMessage):
        """SEC ê³µì‹œ ìˆ˜ì§‘ ìš”ì²­ ì²˜ë¦¬"""
        payload = message.body.get("payload", {})
        ticker = payload.get("ticker", "")
        
        print(f"ğŸ“„ SEC ê³µì‹œ ìˆ˜ì§‘ ì‹œì‘: {ticker}")
        
        try:
            # SEC EDGAR APIë¡œ ê³µì‹œ ìˆ˜ì§‘
            filings_data = await self._fetch_sec_filings(ticker)
            
            # ê²°ê³¼ í¬ë§·íŒ…
            result = {
                "data": filings_data,
                "count": len(filings_data),
                "source": "sec",
                "log_message": f"âœ… {ticker} ê³µì‹œ {len(filings_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ"
            }
            
            # ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ì´ë²¤íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            await self.broadcast_event(
                event_type="data_collected",
                event_data={
                    "source": "sec",
                    "ticker": ticker,
                    "count": len(filings_data)
                }
            )
            
            await self.reply_to_message(message, result=result, success=True)
            
        except Exception as e:
            print(f"âŒ SEC ê³µì‹œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            await self.reply_to_message(
                message,
                result={"error": str(e), "data": [], "count": 0},
                success=False
            )
            
    async def _extract_filing_content(self, filing_url: str, form_type: str) -> Dict[str, Any]:
        """ê³µì‹œ ë¬¸ì„œì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ ë° ë²ˆì—­"""
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.get(
                    filing_url,
                    headers={"User-Agent": self.user_agent}
                )
                
                if response.status_code != 200:
                    return {}
                    
                content = response.text
                
                # HTML ë¬¸ì„œì¸ ê²½ìš° BeautifulSoupìœ¼ë¡œ íŒŒì‹±
                if "<html" in content.lower():
                    soup = BeautifulSoup(content, 'html.parser')
                    text_content = soup.get_text()
                else:
                    text_content = content
                    
                # í¼ íƒ€ì…ë³„ í•µì‹¬ ì •ë³´ ì¶”ì¶œ
                extracted_info = {
                    "filing_url": filing_url,
                    "extraction_timestamp": datetime.now().isoformat()
                }
                
                if form_type == "10-K":
                    # ì—°ê°„ ë³´ê³ ì„œì—ì„œ í•µì‹¬ ì¬ë¬´ ì •ë³´ ì¶”ì¶œ
                    extracted_info.update(await self._extract_10k_info_enhanced(text_content))
                elif form_type == "10-Q":
                    # ë¶„ê¸° ë³´ê³ ì„œì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ
                    extracted_info.update(await self._extract_10q_info_enhanced(text_content))
                elif form_type == "8-K":
                    # ì„ì‹œ ë³´ê³ ì„œì—ì„œ ì£¼ìš” ì´ë²¤íŠ¸ ì¶”ì¶œ
                    extracted_info.update(await self._extract_8k_info_enhanced(text_content))
                elif form_type == "DEF 14A":
                    # ì£¼ì£¼ì´íšŒ ìœ„ì„ì¥ì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ
                    extracted_info.update(await self._extract_proxy_info_enhanced(text_content))
                elif form_type == "13F-HR" or form_type == "13F":
                    # ê¸°ê´€íˆ¬ìì ë³´ìœ  ì£¼ì‹ í˜„í™©
                    extracted_info.update(await self._extract_13f_info_enhanced(text_content, filing_url))
                elif form_type == "4":
                    # Form 4 ë‚´ë¶€ì ê±°ë˜ ë³´ê³ ì„œ
                    extracted_info.update(await self._extract_form4_info_enhanced(text_content))
                
                # 10-K, 10-Qì— ëŒ€í•´ ì¬ë¬´ í…Œì´ë¸” íŒŒì‹± ì‹œë„
                if form_type in ["10-K", "10-Q"]:
                    financial_table_info = await self._extract_financial_tables(content, form_type)
                    extracted_info.update(financial_table_info)
                    
                return extracted_info
                
        except Exception as e:
            print(f"âŒ ê³µì‹œ ë‚´ìš© ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {}
            
    async def _extract_10k_info_enhanced(self, text: str) -> Dict[str, Any]:
        """10-K ì—°ê°„ ë³´ê³ ì„œì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ë° ë²ˆì—­"""
        info = {
            "key_metrics": [],
            "key_metrics_translated": [],
            "risks": [],
            "risks_translated": [],
            "business_highlights": [],
            "business_highlights_translated": [],
            "financial_data": {},
            "md&a_summary": "",
            "md&a_summary_translated": ""
        }
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        text = text.replace('\n', ' ').replace('\t', ' ')
        text = ' '.join(text.split())  # ë‹¤ì¤‘ ê³µë°± ì œê±°
        
        # MD&A (Management Discussion and Analysis) ì„¹ì…˜ ì¶”ì¶œ
        mda_pattern = r"(?:management.?s discussion and analysis|md&a).*?(?=item|part|\Z)"
        mda_match = re.search(mda_pattern, text[:50000], re.IGNORECASE | re.DOTALL)
        if mda_match:
            mda_text = mda_match.group(0)[:2000]  # ì²« 2000ìë§Œ
            # MD&A ìš”ì•½
            summary_sentences = mda_text.split('.')[:5]  # ì²« 5ë¬¸ì¥
            info["md&a_summary"] = '. '.join(summary_sentences)
            info["md&a_summary_translated"] = await translate_text(info["md&a_summary"], "ko")
        
        # ê¸°ì¡´ ì¶”ì¶œ ë¡œì§ ê³„ì†...
        # 1. ë§¤ì¶œ ì •ë³´ ì¶”ì¶œ
        revenue_patterns = [
            r"(?:total\s+)?(?:net\s+)?revenue[s]?(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"(?:total\s+)?net\s+sales(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)"
        ]
        
        for pattern in revenue_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                value = match.group(1).replace(',', '')
                unit = "million" if "million" in match.group(0).lower() else "billion"
                multiplier = 1000000 if unit == "million" else 1000000000
                actual_value = float(value) * multiplier
                
                metric_en = f"Revenue: ${value} {unit}"
                metric_ko = f"ë§¤ì¶œ: ${value} {unit}"
                
                info["key_metrics"].append(metric_en)
                info["key_metrics_translated"].append(metric_ko)
                info["financial_data"]["revenue"] = actual_value
                break
            if info["financial_data"].get("revenue"):
                break
        
        # ë¦¬ìŠ¤í¬ ìš”ì¸ ì¶”ì¶œ (Risk Factors ì„¹ì…˜)
        risk_section_pattern = r"(?:risk factors).*?(?=item|part|\Z)"
        risk_match = re.search(risk_section_pattern, text[:100000], re.IGNORECASE | re.DOTALL)
        if risk_match:
            risk_text = risk_match.group(0)[:5000]
            # ì£¼ìš” ë¦¬ìŠ¤í¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            risk_keywords = [
                "competition", "regulatory", "economic conditions", "cybersecurity",
                "supply chain", "pandemic", "climate change", "litigation"
            ]
            for keyword in risk_keywords:
                if keyword in risk_text.lower():
                    risk_en = f"Risk: {keyword.title()}"
                    risk_ko = await translate_text(risk_en, "ko")
                    info["risks"].append(risk_en)
                    info["risks_translated"].append(risk_ko)
        
        return info
    
    def _extract_10k_info(self, text: str) -> Dict[str, Any]:
        """10-K ì—°ê°„ ë³´ê³ ì„œì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ"""
        info = {
            "key_metrics": [],
            "risks": [],
            "business_highlights": [],
            "financial_data": {}
        }
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        text = text.replace('\n', ' ').replace('\t', ' ')
        text = ' '.join(text.split())  # ë‹¤ì¤‘ ê³µë°± ì œê±°
        
        # 1. ë§¤ì¶œ ì •ë³´ ì¶”ì¶œ (ë” ì •êµí•œ íŒ¨í„´)
        revenue_patterns = [
            r"(?:total\s+)?(?:net\s+)?revenue[s]?(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"(?:total\s+)?net\s+sales(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"(?:total\s+)?revenue[s]?(?:\s+of)?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"revenue[s]?\s+(?:increased|decreased|was).*?\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)"
        ]
        
        for pattern in revenue_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                value = match.group(1).replace(',', '')
                unit = "million" if "million" in match.group(0).lower() else "billion"
                multiplier = 1000000 if unit == "million" else 1000000000
                actual_value = float(value) * multiplier
                info["key_metrics"].append(f"ë§¤ì¶œ: ${value} {unit}")
                info["financial_data"]["revenue"] = actual_value
                break
            if info["financial_data"].get("revenue"):
                break
                
        # 2. ìˆœì´ìµ ì •ë³´ ì¶”ì¶œ
        income_patterns = [
            r"net\s+income(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"net\s+earnings(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"net\s+(?:income|earnings)\s+of\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)"
        ]
        
        for pattern in income_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                value = match.group(1).replace(',', '')
                unit = "million" if "million" in match.group(0).lower() else "billion"
                multiplier = 1000000 if unit == "million" else 1000000000
                actual_value = float(value) * multiplier
                info["key_metrics"].append(f"ìˆœì´ìµ: ${value} {unit}")
                info["financial_data"]["net_income"] = actual_value
                break
            if info["financial_data"].get("net_income"):
                break
                
        # 3. ì˜ì—…ì´ìµ ì¶”ì¶œ
        operating_patterns = [
            r"operating\s+income(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"income\s+from\s+operations(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)"
        ]
        
        for pattern in operating_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                value = match.group(1).replace(',', '')
                unit = "million" if "million" in match.group(0).lower() else "billion"
                info["key_metrics"].append(f"ì˜ì—…ì´ìµ: ${value} {unit}")
                break
                
        # 4. ìì‚° ì •ë³´ ì¶”ì¶œ
        asset_patterns = [
            r"total\s+assets(?:\s+(?:was|were))?\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)",
            r"assets\s+of\s*\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)"
        ]
        
        for pattern in asset_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                value = match.group(1).replace(',', '')
                unit = "million" if "million" in match.group(0).lower() else "billion"
                info["key_metrics"].append(f"ì´ìì‚°: ${value} {unit}")
                break
                
        # 5. ì„±ì¥ë¥  ì¶”ì¶œ
        growth_patterns = [
            r"revenue[s]?\s+(?:increased|grew)(?:\s+by)?\s+([\d.]+)%",
            r"([\d.]+)%\s+(?:increase|growth)\s+in\s+revenue",
            r"revenue[s]?\s+(?:decreased|declined)(?:\s+by)?\s+([\d.]+)%"
        ]
        
        for pattern in growth_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                growth = match.group(1)
                if "decreased" in match.group(0).lower() or "declined" in match.group(0).lower():
                    growth = f"-{growth}"
                info["key_metrics"].append(f"ë§¤ì¶œ ì„±ì¥ë¥ : {growth}%")
                break
                
        # 6. ë¦¬ìŠ¤í¬ íŒ©í„° ì¶”ì¶œ (Risk Factors ì„¹ì…˜ì—ì„œ êµ¬ì²´ì ì¸ ë‚´ìš© ì¶”ì¶œ)
        risk_section = re.search(r"risk\s+factors(.*?)(?:item\s+\d|$)", text, re.IGNORECASE | re.DOTALL)
        if risk_section:
            risk_text = risk_section.group(1)[:2000]  # ì²˜ìŒ 2000ìë§Œ
            
            # ì£¼ìš” ë¦¬ìŠ¤í¬ í‚¤ì›Œë“œ ì°¾ê¸°
            risk_keywords = [
                "competition", "regulatory", "economic conditions", "supply chain",
                "cybersecurity", "pandemic", "climate change", "currency fluctuation",
                "intellectual property", "data privacy", "market volatility"
            ]
            
            found_risks = []
            for keyword in risk_keywords:
                if keyword in risk_text.lower():
                    korean_map = {
                        "competition": "ê²½ìŸ ì‹¬í™”",
                        "regulatory": "ê·œì œ ë¦¬ìŠ¤í¬",
                        "economic conditions": "ê²½ì œ ìƒí™©",
                        "supply chain": "ê³µê¸‰ë§ ë¦¬ìŠ¤í¬",
                        "cybersecurity": "ì‚¬ì´ë²„ë³´ì•ˆ",
                        "pandemic": "íŒ¬ë°ë¯¹ ë¦¬ìŠ¤í¬",
                        "climate change": "ê¸°í›„ë³€í™”",
                        "currency fluctuation": "í™˜ìœ¨ ë³€ë™",
                        "intellectual property": "ì§€ì ì¬ì‚°ê¶Œ",
                        "data privacy": "ë°ì´í„° í”„ë¼ì´ë²„ì‹œ",
                        "market volatility": "ì‹œì¥ ë³€ë™ì„±"
                    }
                    found_risks.append(korean_map.get(keyword, keyword))
            
            if found_risks:
                info["risks"] = found_risks[:5]  # ìƒìœ„ 5ê°œë§Œ
            else:
                info["risks"].append("ì¼ë°˜ì ì¸ ì‚¬ì—… ë¦¬ìŠ¤í¬")
                
        # 7. ì‚¬ì—… í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ
        highlight_keywords = [
            r"launched\s+new\s+product",
            r"acquired\s+(?:company|business)",
            r"expanded\s+(?:into|operations)",
            r"partnership\s+with",
            r"investment\s+in\s+(?:R&D|research)",
            r"market\s+share\s+(?:increased|grew)"
        ]
        
        for pattern in highlight_keywords:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                context = text[max(0, match.start()-50):min(len(text), match.end()+50)]
                info["business_highlights"].append(context.strip())
                
        return info
        
    async def _extract_10q_info_enhanced(self, text: str) -> Dict[str, Any]:
        """10-Q ë¶„ê¸° ë³´ê³ ì„œì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ë° ë²ˆì—­"""
        info = {
            "quarterly_metrics": [],
            "quarterly_metrics_translated": [],
            "segment_performance": [],
            "segment_performance_translated": [],
            "quarter_highlights": "",
            "quarter_highlights_translated": ""
        }
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        text = text.replace('\n', ' ').replace('\t', ' ')
        text = ' '.join(text.split())
        
        # ë¶„ê¸° ë§¤ì¶œ ì¶”ì¶œ
        quarterly_revenue = re.search(
            r"three\s+months.*?revenue.*?\$?([\d,]+(?:\.\d+)?)[\s]?(?:million|billion)",
            text, re.IGNORECASE
        )
        if quarterly_revenue:
            value = quarterly_revenue.group(1)
            metric_en = f"Quarterly Revenue: ${value}"
            metric_ko = f"ë¶„ê¸° ë§¤ì¶œ: ${value}"
            info["quarterly_metrics"].append(metric_en)
            info["quarterly_metrics_translated"].append(metric_ko)
            
        # ì „ë…„ ëŒ€ë¹„ ì„±ì¥ë¥ 
        yoy_pattern = re.search(
            r"compared\s+to.*?prior\s+year.*?([\d.]+)%",
            text, re.IGNORECASE
        )
        if yoy_pattern:
            growth = yoy_pattern.group(1)
            metric_en = f"YoY Growth: {growth}%"
            metric_ko = f"ì „ë…„ ëŒ€ë¹„ ì„±ì¥ë¥ : {growth}%"
            info["quarterly_metrics"].append(metric_en)
            info["quarterly_metrics_translated"].append(metric_ko)
        
        # ì„¸ê·¸ë¨¼íŠ¸ë³„ ì‹¤ì  ì¶”ì¶œ
        segment_pattern = r"segment.*?revenue.*?\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)"
        segment_matches = re.finditer(segment_pattern, text[:5000], re.IGNORECASE)
        for match in segment_matches[:3]:  # ìµœëŒ€ 3ê°œ
            segment_info = match.group(0)
            translated = await translate_text(segment_info, "ko")
            info["segment_performance"].append(segment_info)
            info["segment_performance_translated"].append(translated)
        
        # ë¶„ê¸° í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ
        highlight_section = re.search(
            r"(?:highlights|overview).*?(?=item|part|financial|$)",
            text[:3000], re.IGNORECASE | re.DOTALL
        )
        if highlight_section:
            highlights = highlight_section.group(0)[:500]
            info["quarter_highlights"] = highlights
            info["quarter_highlights_translated"] = await translate_text(highlights, "ko")
        
        return info
        
    def _extract_10q_info(self, text: str) -> Dict[str, Any]:
        """10-Q ë¶„ê¸° ë³´ê³ ì„œì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ"""
        info = {
            "quarterly_metrics": [],
            "segment_performance": []
        }
        
        # ë¶„ê¸° ë§¤ì¶œ ì¶”ì¶œ
        quarterly_revenue = re.search(
            r"three\s+months.*?revenue.*?\$?([\d,]+(?:\.\d+)?)[\s]?(?:million|billion)",
            text, re.IGNORECASE
        )
        if quarterly_revenue:
            info["quarterly_metrics"].append(f"ë¶„ê¸° ë§¤ì¶œ: ${quarterly_revenue.group(1)}")
            
        # ì „ë…„ ëŒ€ë¹„ ì„±ì¥ë¥ 
        growth_pattern = re.search(
            r"(?:increased?|decreased?|grew|declined?).*?([\d]+(?:\.\d+)?)\s*%",
            text, re.IGNORECASE
        )
        if growth_pattern:
            info["quarterly_metrics"].append(f"ì„±ì¥ë¥ : {growth_pattern.group(1)}%")
            
        return info
        
    async def _extract_8k_info_enhanced(self, text: str) -> Dict[str, Any]:
        """8-K ì„ì‹œ ë³´ê³ ì„œì—ì„œ ìƒì„¸ ì´ë²¤íŠ¸ ì •ë³´ ì¶”ì¶œ ë° ë²ˆì—­"""
        info = {
            "events": [],
            "events_translated": [],
            "event_details": [],
            "event_details_translated": [],
            "material_changes": "",
            "material_changes_translated": ""
        }
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        text = text.replace('\n', ' ').replace('\t', ' ')
        text = ' '.join(text.split())
        
        # Itemë³„ ì¤‘ìš” ì´ë²¤íŠ¸ ë§¤í•‘
        item_patterns = {
            "Item 1.01": "ì¤‘ìš” ê³„ì•½ ì²´ê²°",
            "Item 2.01": "ìì‚° ì¸ìˆ˜ ì™„ë£Œ",
            "Item 2.02": "ìš´ì˜ ê²°ê³¼ ë° ì¬ë¬´ ìƒíƒœ",
            "Item 2.03": "ì¤‘ìš” ì˜ë¬´ ë°œìƒ",
            "Item 2.05": "ì‚¬ì—… ì¤‘ë‹¨ ë¹„ìš©",
            "Item 3.01": "íŒŒì‚° ë˜ëŠ” ë²•ì •ê´€ë¦¬",
            "Item 5.02": "ì„ì› ë³€ê²½",
            "Item 5.03": "ì •ê´€ ë˜ëŠ” ê·œì • ë³€ê²½",
            "Item 7.01": "ê·œì œ ê³µì‹œ",
            "Item 8.01": "ê¸°íƒ€ ì¤‘ìš” ì‚¬í•­"
        }
        
        # Itemë³„ ì´ë²¤íŠ¸ ì¶”ì¶œ
        for item_code, item_desc in item_patterns.items():
            pattern = f"{item_code}.*?(?=Item|$)"
            match = re.search(pattern, text[:10000], re.IGNORECASE)
            if match:
                event_text = match.group(0)[:500]
                event_en = f"{item_code}: {event_text[:200]}..."
                event_ko = f"{item_code}: {item_desc}"
                
                info["events"].append(event_en)
                info["events_translated"].append(event_ko)
                
                # ìƒì„¸ ë‚´ìš© ì¶”ì¶œ
                detail_text = event_text[:300]
                detail_translated = await translate_text(detail_text, "ko")
                info["event_details"].append(detail_text)
                info["event_details_translated"].append(detail_translated)
        
        # ì¤‘ìš” ë³€ê²½ì‚¬í•­ ìš”ì•½
        material_section = re.search(
            r"(?:material|significant).*?(?:change|development|event).*?(?=\.|$)",
            text[:2000], re.IGNORECASE
        )
        if material_section:
            material_text = material_section.group(0)
            info["material_changes"] = material_text
            info["material_changes_translated"] = await translate_text(material_text, "ko")
        
        return info
    
    def _extract_8k_info(self, text: str) -> Dict[str, Any]:
        """8-K ì„ì‹œ ë³´ê³ ì„œì—ì„œ ì£¼ìš” ì´ë²¤íŠ¸ ì¶”ì¶œ"""
        info = {
            "events": [],
            "material_changes": []
        }
        
        # ì£¼ìš” ì´ë²¤íŠ¸ í‚¤ì›Œë“œ
        event_keywords = {
            "acquisition": "ì¸ìˆ˜í•©ë³‘",
            "merger": "í•©ë³‘",
            "resignation": "ê²½ì˜ì§„ ì‚¬ì„",
            "appointment": "ì‹ ê·œ ì„ëª…",
            "dividend": "ë°°ë‹¹ ë°œí‘œ",
            "buyback": "ìì‚¬ì£¼ ë§¤ì…",
            "restructuring": "êµ¬ì¡°ì¡°ì •",
            "litigation": "ì†Œì†¡",
            "partnership": "íŒŒíŠ¸ë„ˆì‹­",
            "product launch": "ì‹ ì œí’ˆ ì¶œì‹œ"
        }
        
        for eng, kor in event_keywords.items():
            if eng in text.lower():
                info["events"].append(kor)
                
        return info
        
    async def _extract_proxy_info_enhanced(self, text: str) -> Dict[str, Any]:
        """DEF 14A ì£¼ì£¼ì´íšŒ ìœ„ì„ì¥ì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ë° ë²ˆì—­"""
        info = {
            "executive_compensation": [],
            "executive_compensation_translated": [],
            "proposals": [],
            "proposals_translated": [],
            "board_changes": [],
            "board_changes_translated": [],
            "governance_highlights": "",
            "governance_highlights_translated": ""
        }
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        text = text.replace('\n', ' ').replace('\t', ' ')
        text = ' '.join(text.split())
        
        # ì„ì› ë³´ìˆ˜ ì •ë³´ ì¶”ì¶œ
        comp_patterns = [
            r"(?:CEO|chief executive).*?compensation.*?\$?([\d,]+(?:\.\d+)?)\s*(?:million|thousand)?",
            r"named executive officers.*?total.*?\$?([\d,]+(?:\.\d+)?)\s*(?:million|thousand)?",
            r"total compensation.*?\$?([\d,]+(?:\.\d+)?)\s*(?:million|thousand)?"
        ]
        
        for pattern in comp_patterns[:3]:  # ìµœëŒ€ 3ê°œ
            match = re.search(pattern, text[:10000], re.IGNORECASE)
            if match:
                comp_info = match.group(0)
                comp_translated = await translate_text(comp_info, "ko")
                info["executive_compensation"].append(comp_info)
                info["executive_compensation_translated"].append(comp_translated)
        
        # ì£¼ì£¼ ì œì•ˆ ì¶”ì¶œ
        proposal_pattern = r"proposal\s*\d+.*?(?=proposal|$)"
        proposal_matches = re.finditer(proposal_pattern, text[:20000], re.IGNORECASE)
        
        for i, match in enumerate(proposal_matches):
            if i >= 5:  # ìµœëŒ€ 5ê°œ ì œì•ˆ
                break
            proposal_text = match.group(0)[:300]
            proposal_translated = await translate_text(proposal_text, "ko")
            info["proposals"].append(proposal_text)
            info["proposals_translated"].append(proposal_translated)
        
        # ì´ì‚¬íšŒ ë³€ê²½ì‚¬í•­
        board_patterns = [
            r"(?:elect|nominate|appoint).*?director",
            r"board.*?(?:resignation|retirement)",
            r"new.*?board member"
        ]
        
        for pattern in board_patterns:
            match = re.search(pattern, text[:10000], re.IGNORECASE)
            if match:
                board_info = text[max(0, match.start()-100):match.end()+100]
                board_translated = await translate_text(board_info, "ko")
                info["board_changes"].append(board_info)
                info["board_changes_translated"].append(board_translated)
        
        # ê±°ë²„ë„ŒìŠ¤ í•˜ì´ë¼ì´íŠ¸
        governance_section = re.search(
            r"(?:corporate governance|governance highlights).*?(?=item|proposal|$)",
            text[:5000], re.IGNORECASE | re.DOTALL
        )
        if governance_section:
            governance_text = governance_section.group(0)[:500]
            info["governance_highlights"] = governance_text
            info["governance_highlights_translated"] = await translate_text(governance_text, "ko")
        
        return info
    
    async def _extract_13f_info_enhanced(self, text: str, filing_url: str) -> Dict[str, Any]:
        """13F-HR ê¸°ê´€íˆ¬ìì ë³´ìœ  í˜„í™©ì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ë° ë²ˆì—­"""
        info = {
            "institution_name": "",
            "institution_name_translated": "",
            "total_value": 0,
            "total_value_translated": "",
            "top_holdings": [],
            "top_holdings_translated": [],
            "position_changes": [],
            "position_changes_translated": [],
            "portfolio_insights": "",
            "portfolio_insights_translated": ""
        }
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        text = text.replace('\n', ' ').replace('\t', ' ')
        text = ' '.join(text.split())
        
        # 1. ê¸°ê´€ ì´ë¦„ ì¶”ì¶œ
        institution_pattern = re.search(
            r"(?:filed by|reporting person|manager).*?(?:name|entity).*?([A-Z][A-Za-z\s&,.\-]+(?:LLC|LP|Inc|Corp|Company|Partners|Capital|Management|Advisors))",
            text[:2000], re.IGNORECASE
        )
        if institution_pattern:
            info["institution_name"] = institution_pattern.group(1).strip()
            info["institution_name_translated"] = await translate_text(info["institution_name"], "ko")
        
        # 2. ì´ í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ì¶”ì¶œ
        value_pattern = re.search(
            r"(?:total value|aggregate value|market value).*?\$?([\d,]+(?:\.\d+)?)\s*(?:thousand|million|billion)?",
            text, re.IGNORECASE
        )
        if value_pattern:
            value_str = value_pattern.group(1).replace(',', '')
            multiplier = 1
            if "billion" in value_pattern.group(0).lower():
                multiplier = 1000000000
            elif "million" in value_pattern.group(0).lower():
                multiplier = 1000000
            elif "thousand" in value_pattern.group(0).lower():
                multiplier = 1000
            
            info["total_value"] = float(value_str) * multiplier
            info["total_value_translated"] = f"ì´ ìš´ìš©ìì‚°: ${info['total_value']:,.0f}"
        
        # 3. ì£¼ìš” ë³´ìœ  ì¢…ëª© ì¶”ì¶œ (ìƒìœ„ 10ê°œ)
        # 13FëŠ” ì£¼ë¡œ í…Œì´ë¸” í˜•ì‹ì´ë¯€ë¡œ ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­
        holdings_pattern = re.findall(
            r"([A-Z]{2,5})\s+(?:COM|COMMON|ORD).*?([\d,]+)\s+(?:SH|SHARES).*?\$?([\d,]+(?:\.\d+)?)",
            text[:20000], re.IGNORECASE
        )
        
        for i, (ticker, shares, value) in enumerate(holdings_pattern[:10]):
            shares_num = int(shares.replace(',', ''))
            value_num = float(value.replace(',', ''))
            
            holding_en = f"{ticker}: {shares_num:,} shares (${value_num:,.0f})"
            holding_ko = f"{ticker}: {shares_num:,}ì£¼ (${value_num:,.0f})"
            
            info["top_holdings"].append(holding_en)
            info["top_holdings_translated"].append(holding_ko)
        
        # 4. í¬ì§€ì…˜ ë³€ê²½ì‚¬í•­ ë¶„ì„
        # NEW, INCREASED, DECREASED, SOLD OUT í‚¤ì›Œë“œ ì°¾ê¸°
        new_positions = re.findall(r"NEW\s+POSITION.*?([A-Z]{2,5})", text, re.IGNORECASE)
        increased = re.findall(r"INCREASED.*?([A-Z]{2,5})", text, re.IGNORECASE)
        decreased = re.findall(r"DECREASED.*?([A-Z]{2,5})", text, re.IGNORECASE)
        sold_out = re.findall(r"SOLD\s+OUT.*?([A-Z]{2,5})", text, re.IGNORECASE)
        
        if new_positions:
            change_en = f"New positions: {', '.join(new_positions[:5])}"
            change_ko = f"ì‹ ê·œ ë§¤ìˆ˜: {', '.join(new_positions[:5])}"
            info["position_changes"].append(change_en)
            info["position_changes_translated"].append(change_ko)
            
        if increased:
            change_en = f"Increased positions: {', '.join(increased[:5])}"
            change_ko = f"ë¹„ì¤‘ í™•ëŒ€: {', '.join(increased[:5])}"
            info["position_changes"].append(change_en)
            info["position_changes_translated"].append(change_ko)
            
        if decreased:
            change_en = f"Reduced positions: {', '.join(decreased[:5])}"
            change_ko = f"ë¹„ì¤‘ ì¶•ì†Œ: {', '.join(decreased[:5])}"
            info["position_changes"].append(change_en)
            info["position_changes_translated"].append(change_ko)
            
        if sold_out:
            change_en = f"Sold out: {', '.join(sold_out[:5])}"
            change_ko = f"ì „ëŸ‰ ë§¤ë„: {', '.join(sold_out[:5])}"
            info["position_changes"].append(change_en)
            info["position_changes_translated"].append(change_ko)
        
        # 5. í¬íŠ¸í´ë¦¬ì˜¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        if info["top_holdings"]:
            top_3_tickers = [h.split(':')[0] for h in info["top_holdings"][:3]]
            insight_en = f"Top holdings include {', '.join(top_3_tickers)}. "
            
            if new_positions:
                insight_en += f"Notable new positions in {', '.join(new_positions[:3])}. "
            
            sector_keywords = ["TECH", "FINANCE", "HEALTHCARE", "ENERGY", "CONSUMER"]
            dominant_sector = None
            for sector in sector_keywords:
                if text.count(sector) > 5:
                    dominant_sector = sector
                    break
            
            if dominant_sector:
                insight_en += f"Portfolio shows concentration in {dominant_sector} sector."
            
            info["portfolio_insights"] = insight_en
            info["portfolio_insights_translated"] = await translate_text(insight_en, "ko")
        
        return info
    
    async def _extract_form4_info_enhanced(self, text: str) -> Dict[str, Any]:
        """Form 4 ë‚´ë¶€ì ê±°ë˜ ë³´ê³ ì„œì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ë° ë²ˆì—­"""
        info = {
            "reporting_person": "",
            "reporting_person_translated": "",
            "person_title": "",
            "person_title_translated": "",
            "transaction_date": "",
            "transactions": [],
            "transactions_translated": [],
            "total_shares_owned": 0,
            "total_value_owned": 0,
            "ownership_percentage": 0,
            "insider_sentiment": "",
            "insider_sentiment_translated": "",
            "transaction_summary": "",
            "transaction_summary_translated": ""
        }
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        text = text.replace('\n', ' ').replace('\t', ' ')
        text = ' '.join(text.split())
        
        # 1. ë³´ê³ ì ì •ë³´ ì¶”ì¶œ
        reporter_pattern = re.search(
            r"(?:reporting person|name).*?([A-Z][a-zA-Z\s,.']+)(?=\s+(?:title|director|officer|CEO|CFO|CTO|President|VP|Chief))",
            text[:3000], re.IGNORECASE
        )
        if reporter_pattern:
            info["reporting_person"] = reporter_pattern.group(1).strip()
            info["reporting_person_translated"] = await translate_text(info["reporting_person"], "ko")
        
        # 2. ì§ì±… ì¶”ì¶œ
        title_pattern = re.search(
            r"(?:title|relationship).*?((?:CEO|CFO|CTO|COO|President|Vice President|VP|Director|Chief [A-Za-z]+ Officer|Executive [A-Za-z]+|Senior [A-Za-z]+)[^,.\n]*)",
            text[:3000], re.IGNORECASE
        )
        if title_pattern:
            info["person_title"] = title_pattern.group(1).strip()
            info["person_title_translated"] = await translate_text(info["person_title"], "ko")
        
        # 3. ê±°ë˜ ë‚ ì§œ ì¶”ì¶œ
        date_pattern = re.search(
            r"(?:transaction date|date of transaction).*?(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})",
            text, re.IGNORECASE
        )
        if date_pattern:
            info["transaction_date"] = date_pattern.group(1)
        
        # 4. ê±°ë˜ ë‚´ì—­ ì¶”ì¶œ
        # Table I - ë¹„íŒŒìƒ ì¦ê¶Œ ê±°ë˜
        transaction_patterns = re.findall(
            r"(?:acquired|disposed|purchase|sale|grant|exercise).*?(\d+[\d,]*)\s*(?:shares?|stock).*?(?:price|@).*?\$?([\d.]+)",
            text[:10000], re.IGNORECASE
        )
        
        total_acquired = 0
        total_disposed = 0
        
        for i, match in enumerate(transaction_patterns[:10]):  # ìµœëŒ€ 10ê°œ ê±°ë˜
            shares_str = match[0].replace(',', '')
            shares = int(shares_str)
            price = float(match[1])
            
            # ê±°ë˜ ìœ í˜• íŒë‹¨
            context = text[max(0, text.find(match[0])-50):text.find(match[0])+100]
            
            if any(word in context.lower() for word in ['acquired', 'purchase', 'grant', 'exercise']):
                transaction_type = "ë§¤ìˆ˜"
                transaction_type_en = "Acquired"
                total_acquired += shares
            else:
                transaction_type = "ë§¤ë„"
                transaction_type_en = "Disposed"
                total_disposed += shares
            
            # ê±°ë˜ ì½”ë“œ ì¶”ì¶œ
            code_match = re.search(r"code[:\s]*([A-Z])", context, re.IGNORECASE)
            transaction_code = code_match.group(1) if code_match else ""
            
            # ê±°ë˜ ì½”ë“œ ì„¤ëª…
            code_descriptions = {
                "P": "ê³µê°œì‹œì¥ ë§¤ìˆ˜ (Open Market Purchase)",
                "S": "ê³µê°œì‹œì¥ ë§¤ë„ (Open Market Sale)",
                "A": "ìˆ˜ì—¬/ë³´ìƒ (Grant/Award)",
                "M": "ì˜µì…˜ í–‰ì‚¬ (Option Exercise)",
                "F": "ì„¸ê¸ˆ ë‚©ë¶€ìš© ì£¼ì‹ ì²˜ë¶„ (Tax Withholding)",
                "D": "ê¸°íƒ€ ì²˜ë¶„ (Disposition)",
                "G": "ì¦ì—¬ (Gift)"
            }
            
            code_desc = code_descriptions.get(transaction_code, "ê¸°íƒ€ ê±°ë˜")
            
            transaction_en = f"{transaction_type_en} {shares:,} shares at ${price:.2f} (Code: {transaction_code})"
            transaction_ko = f"{transaction_type} {shares:,}ì£¼ @ ${price:.2f} ({code_desc})"
            
            info["transactions"].append(transaction_en)
            info["transactions_translated"].append(transaction_ko)
        
        # 5. ê±°ë˜ í›„ ë³´ìœ  ì£¼ì‹ ìˆ˜ ì¶”ì¶œ
        ownership_pattern = re.search(
            r"(?:owned following|shares beneficially owned|total).*?(\d+[\d,]*)\s*(?:shares?|stock)",
            text, re.IGNORECASE
        )
        if ownership_pattern:
            info["total_shares_owned"] = int(ownership_pattern.group(1).replace(',', ''))
            
            # í˜„ì¬ ì£¼ê°€ë¡œ ë³´ìœ  ê°€ì¹˜ ì¶”ì • (ì‹¤ì œë¡œëŠ” ì£¼ê°€ ë°ì´í„° í•„ìš”)
            if transaction_patterns and len(transaction_patterns) > 0:
                last_price = float(transaction_patterns[-1][1])
                info["total_value_owned"] = info["total_shares_owned"] * last_price
        
        # 6. ì†Œìœ  ë¹„ìœ¨ ì¶”ì¶œ
        percentage_pattern = re.search(
            r"(?:ownership|percent|%).*?([\d.]+)\s*%",
            text, re.IGNORECASE
        )
        if percentage_pattern:
            info["ownership_percentage"] = float(percentage_pattern.group(1))
        
        # 7. ë‚´ë¶€ì ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„
        if total_acquired > total_disposed:
            sentiment_ratio = (total_acquired - total_disposed) / (total_acquired + total_disposed) if (total_acquired + total_disposed) > 0 else 0
            if sentiment_ratio > 0.5:
                info["insider_sentiment"] = "Strong Buy Signal"
                info["insider_sentiment_translated"] = "ê°•ë ¥í•œ ë§¤ìˆ˜ ì‹ í˜¸"
            else:
                info["insider_sentiment"] = "Moderate Buy Signal"
                info["insider_sentiment_translated"] = "ë³´í†µ ë§¤ìˆ˜ ì‹ í˜¸"
        elif total_disposed > total_acquired:
            sentiment_ratio = (total_disposed - total_acquired) / (total_acquired + total_disposed) if (total_acquired + total_disposed) > 0 else 0
            if sentiment_ratio > 0.5:
                info["insider_sentiment"] = "Strong Sell Signal"
                info["insider_sentiment_translated"] = "ê°•ë ¥í•œ ë§¤ë„ ì‹ í˜¸"
            else:
                info["insider_sentiment"] = "Moderate Sell Signal"
                info["insider_sentiment_translated"] = "ë³´í†µ ë§¤ë„ ì‹ í˜¸"
        else:
            info["insider_sentiment"] = "Neutral"
            info["insider_sentiment_translated"] = "ì¤‘ë¦½"
        
        # 8. ê±°ë˜ ìš”ì•½ ìƒì„±
        if info["reporting_person"] and info["transactions"]:
            summary_en = f"{info['reporting_person']} ({info['person_title']}) "
            
            if total_acquired > 0:
                summary_en += f"acquired {total_acquired:,} shares"
            if total_disposed > 0:
                if total_acquired > 0:
                    summary_en += " and "
                summary_en += f"disposed {total_disposed:,} shares"
            
            summary_en += f". Now owns {info['total_shares_owned']:,} shares"
            if info['ownership_percentage'] > 0:
                summary_en += f" ({info['ownership_percentage']:.2f}% ownership)"
            
            info["transaction_summary"] = summary_en
            info["transaction_summary_translated"] = await translate_text(summary_en, "ko")
        
        return info
    
    async def _extract_financial_tables(self, text: str, form_type: str) -> Dict[str, Any]:
        """ì¬ë¬´ì œí‘œ í…Œì´ë¸” ì¶”ì¶œ ë° êµ¬ì¡°í™”"""
        info = {
            "financial_statements": {},
            "financial_statements_translated": {},
            "key_ratios": {},
            "key_ratios_translated": {},
            "year_over_year_changes": {},
            "quarter_over_quarter_changes": {},
            "financial_highlights": "",
            "financial_highlights_translated": ""
        }
        
        # HTML ì½˜í…ì¸ ì¸ì§€ í™•ì¸
        soup = BeautifulSoup(text, 'html.parser')
        tables = soup.find_all('table')
        
        if not tables:
            # í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¬ë¬´ ë°ì´í„° ì¶”ì¶œ ì‹œë„
            return await self._extract_financial_data_from_text(text, form_type)
        
        # ì¬ë¬´ì œí‘œ íƒ€ì… ì‹ë³„ íŒ¨í„´
        statement_patterns = {
            "income_statement": [
                "income statement", "statement of income", "statement of operations",
                "statement of earnings", "consolidated statements of income"
            ],
            "balance_sheet": [
                "balance sheet", "statement of financial position",
                "consolidated balance sheets"
            ],
            "cash_flow": [
                "cash flow", "statement of cash flows", "cash flows statement"
            ]
        }
        
        for table in tables[:10]:  # ìµœëŒ€ 10ê°œ í…Œì´ë¸” ê²€ì‚¬
            # í…Œì´ë¸” í…ìŠ¤íŠ¸ ì¶”ì¶œ
            table_text = table.get_text().lower()
            
            # ì¬ë¬´ì œí‘œ íƒ€ì… ì‹ë³„
            statement_type = None
            for stmt_type, patterns in statement_patterns.items():
                if any(pattern in table_text for pattern in patterns):
                    statement_type = stmt_type
                    break
            
            if not statement_type:
                continue
            
            try:
                # pandasë¡œ í…Œì´ë¸” íŒŒì‹±
                df = pd.read_html(StringIO(str(table)))[0]
                
                # ë°ì´í„° ì •ë¦¬ ë° ìˆ«ì ë³€í™˜
                df = self._clean_financial_dataframe(df)
                
                # ì¬ë¬´ì œí‘œ ì €ì¥
                info["financial_statements"][statement_type] = df.to_dict('records')
                
                # ì£¼ìš” í•­ëª© ì¶”ì¶œ ë° ë²ˆì—­
                if statement_type == "income_statement":
                    await self._extract_income_statement_items(df, info)
                elif statement_type == "balance_sheet":
                    await self._extract_balance_sheet_items(df, info)
                elif statement_type == "cash_flow":
                    await self._extract_cash_flow_items(df, info)
                    
            except Exception as e:
                logger.warning(f"í…Œì´ë¸” íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                continue
        
        # ì¬ë¬´ ë¹„ìœ¨ ê³„ì‚°
        if info["financial_statements"]:
            self._calculate_financial_ratios(info)
        
        # ì¬ë¬´ í•˜ì´ë¼ì´íŠ¸ ìƒì„±
        if info["key_ratios"]:
            highlights = self._generate_financial_highlights(info)
            info["financial_highlights"] = highlights
            info["financial_highlights_translated"] = await translate_text(highlights, "ko")
        
        return info
    
    def _clean_financial_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì¬ë¬´ ë°ì´í„°í”„ë ˆì„ ì •ë¦¬ ë° ìˆ«ì ë³€í™˜"""
        # ì—´ ì´ë¦„ ì •ë¦¬
        df.columns = [str(col).strip() for col in df.columns]
        
        # ìˆ«ì ë³€í™˜ í•¨ìˆ˜
        def convert_to_number(value):
            if pd.isna(value) or value == '-' or value == 'â€”':
                return 0
            
            # ë¬¸ìì—´ë¡œ ë³€í™˜
            val_str = str(value).strip()
            
            # ê´„í˜¸ ì œê±° (ìŒìˆ˜ í‘œì‹œ)
            is_negative = False
            if val_str.startswith('(') and val_str.endswith(')'):
                is_negative = True
                val_str = val_str[1:-1]
            
            # íŠ¹ìˆ˜ ë¬¸ì ì œê±°
            val_str = val_str.replace('$', '').replace(',', '').replace('%', '')
            
            try:
                number = float(val_str)
                return -number if is_negative else number
            except:
                return 0
        
        # ìˆ«ì ì—´ ë³€í™˜
        for col in df.columns[1:]:  # ì²« ë²ˆì§¸ ì—´ì€ ë³´í†µ í•­ëª©ëª…
            df[col] = df[col].apply(convert_to_number)
        
        return df
    
    async def _extract_income_statement_items(self, df: pd.DataFrame, info: Dict[str, Any]):
        """ì†ìµê³„ì‚°ì„œ ì£¼ìš” í•­ëª© ì¶”ì¶œ"""
        # ì£¼ìš” í•­ëª© ë§¤í•‘
        key_items = {
            "revenue": ["revenue", "net revenue", "total revenue", "net sales"],
            "gross_profit": ["gross profit", "gross margin"],
            "operating_income": ["operating income", "income from operations"],
            "net_income": ["net income", "net earnings"],
            "eps": ["earnings per share", "eps", "diluted eps"]
        }
        
        extracted_items = {}
        
        for item_name, patterns in key_items.items():
            for idx, row in df.iterrows():
                row_text = str(row[0]).lower()
                if any(pattern in row_text for pattern in patterns):
                    # ìµœì‹  ë°ì´í„° (ë³´í†µ ë§ˆì§€ë§‰ ì—´)
                    if len(df.columns) > 1:
                        value = row[df.columns[-1]]
                        extracted_items[item_name] = value
                        
                        # ì „ë…„ ëŒ€ë¹„ ë³€í™”ìœ¨ ê³„ì‚°
                        if len(df.columns) > 2:
                            prev_value = row[df.columns[-2]]
                            if prev_value != 0:
                                change = ((value - prev_value) / abs(prev_value)) * 100
                                info["year_over_year_changes"][item_name] = f"{change:.1f}%"
        
        # í•œêµ­ì–´ ë²ˆì—­
        item_translations = {
            "revenue": "ë§¤ì¶œ",
            "gross_profit": "ë§¤ì¶œì´ì´ìµ",
            "operating_income": "ì˜ì—…ì´ìµ",
            "net_income": "ìˆœì´ìµ",
            "eps": "ì£¼ë‹¹ìˆœì´ìµ"
        }
        
        for key, value in extracted_items.items():
            korean_name = item_translations.get(key, key)
            info["financial_statements_translated"][f"{korean_name}"] = f"${value:,.0f}"
        
        # ì¬ë¬´ ë¹„ìœ¨ ê³„ì‚°ìš© ë°ì´í„° ì €ì¥
        info["income_statement_data"] = extracted_items
    
    async def _extract_balance_sheet_items(self, df: pd.DataFrame, info: Dict[str, Any]):
        """ëŒ€ì°¨ëŒ€ì¡°í‘œ ì£¼ìš” í•­ëª© ì¶”ì¶œ"""
        key_items = {
            "total_assets": ["total assets"],
            "current_assets": ["current assets", "total current assets"],
            "total_liabilities": ["total liabilities"],
            "current_liabilities": ["current liabilities", "total current liabilities"],
            "shareholders_equity": ["shareholders' equity", "stockholders' equity", "total equity"]
        }
        
        extracted_items = {}
        
        for item_name, patterns in key_items.items():
            for idx, row in df.iterrows():
                row_text = str(row[0]).lower()
                if any(pattern in row_text for pattern in patterns):
                    if len(df.columns) > 1:
                        value = row[df.columns[-1]]
                        extracted_items[item_name] = value
        
        # ì¬ë¬´ ë¹„ìœ¨ìš© ë°ì´í„° ì €ì¥
        info["balance_sheet_data"] = extracted_items
    
    async def _extract_cash_flow_items(self, df: pd.DataFrame, info: Dict[str, Any]):
        """í˜„ê¸ˆíë¦„í‘œ ì£¼ìš” í•­ëª© ì¶”ì¶œ"""
        key_items = {
            "operating_cash_flow": ["cash from operating", "net cash provided by operating"],
            "investing_cash_flow": ["cash from investing", "net cash used in investing"],
            "financing_cash_flow": ["cash from financing", "net cash used in financing"],
            "free_cash_flow": ["free cash flow"]
        }
        
        extracted_items = {}
        
        for item_name, patterns in key_items.items():
            for idx, row in df.iterrows():
                row_text = str(row[0]).lower()
                if any(pattern in row_text for pattern in patterns):
                    if len(df.columns) > 1:
                        value = row[df.columns[-1]]
                        extracted_items[item_name] = value
        
        # ì‰ì—¬í˜„ê¸ˆíë¦„ ê³„ì‚° (ì˜ì—…í˜„ê¸ˆíë¦„ - íˆ¬ìí˜„ê¸ˆíë¦„)
        if "operating_cash_flow" in extracted_items and "investing_cash_flow" not in extracted_items:
            # íˆ¬ìí˜„ê¸ˆíë¦„ì´ ì—†ìœ¼ë©´ CAPEX ì°¾ê¸°
            for idx, row in df.iterrows():
                if "capital expenditure" in str(row[0]).lower() or "capex" in str(row[0]).lower():
                    if len(df.columns) > 1:
                        capex = abs(row[df.columns[-1]])
                        extracted_items["free_cash_flow"] = extracted_items["operating_cash_flow"] - capex
    
    def _calculate_financial_ratios(self, info: Dict[str, Any]):
        """ì£¼ìš” ì¬ë¬´ ë¹„ìœ¨ ê³„ì‚°"""
        ratios = {}
        
        # ìˆ˜ìµì„± ë¹„ìœ¨
        if "income_statement" in info["financial_statements"]:
            income_data = info.get("income_statement_data", {})
            if income_data.get("revenue") and income_data.get("net_income"):
                ratios["net_margin"] = (income_data["net_income"] / income_data["revenue"]) * 100
                info["key_ratios"]["net_margin"] = f"{ratios['net_margin']:.1f}%"
                info["key_ratios_translated"]["ìˆœì´ìµë¥ "] = f"{ratios['net_margin']:.1f}%"
        
        # ìœ ë™ì„± ë¹„ìœ¨
        if "balance_sheet_data" in info:
            bs_data = info["balance_sheet_data"]
            if bs_data.get("current_assets") and bs_data.get("current_liabilities"):
                current_ratio = bs_data["current_assets"] / bs_data["current_liabilities"]
                info["key_ratios"]["current_ratio"] = f"{current_ratio:.2f}"
                info["key_ratios_translated"]["ìœ ë™ë¹„ìœ¨"] = f"{current_ratio:.2f}"
            
            # ë¶€ì±„ë¹„ìœ¨
            if bs_data.get("total_liabilities") and bs_data.get("shareholders_equity"):
                debt_to_equity = bs_data["total_liabilities"] / bs_data["shareholders_equity"]
                info["key_ratios"]["debt_to_equity"] = f"{debt_to_equity:.2f}"
                info["key_ratios_translated"]["ë¶€ì±„ë¹„ìœ¨"] = f"{debt_to_equity:.2f}"
    
    def _generate_financial_highlights(self, info: Dict[str, Any]) -> str:
        """ì¬ë¬´ í•˜ì´ë¼ì´íŠ¸ ìƒì„±"""
        highlights = []
        
        if info.get("year_over_year_changes"):
            for item, change in info["year_over_year_changes"].items():
                highlights.append(f"{item} YoY change: {change}")
        
        if info.get("key_ratios"):
            for ratio, value in info["key_ratios"].items():
                highlights.append(f"{ratio}: {value}")
        
        return ". ".join(highlights[:5])  # ìƒìœ„ 5ê°œë§Œ
    
    async def _extract_financial_data_from_text(self, text: str, form_type: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì¬ë¬´ ë°ì´í„° ì¶”ì¶œ (í…Œì´ë¸”ì´ ì—†ëŠ” ê²½ìš°)"""
        info = {
            "financial_data_text": [],
            "financial_data_text_translated": []
        }
        
        # ì¬ë¬´ ë°ì´í„° íŒ¨í„´
        financial_patterns = [
            (r"revenue.*?\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)", "Revenue"),
            (r"net income.*?\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)", "Net Income"),
            (r"earnings per.*?\$?([\d.]+)", "EPS"),
            (r"total assets.*?\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)", "Total Assets"),
            (r"cash and cash equivalents.*?\$?([\d,]+(?:\.\d+)?)\s*(?:million|billion)", "Cash")
        ]
        
        for pattern, label in financial_patterns:
            match = re.search(pattern, text[:50000], re.IGNORECASE)
            if match:
                value = match.group(1)
                unit = "billion" if "billion" in match.group(0).lower() else "million"
                
                data_en = f"{label}: ${value} {unit}"
                data_ko = await translate_text(data_en, "ko")
                
                info["financial_data_text"].append(data_en)
                info["financial_data_text_translated"].append(data_ko)
        
        return info
    
    async def _compare_filings(self, ticker: str, current_filing: Dict[str, Any], 
                              filing_type: str) -> Dict[str, Any]:
        """ì´ì „ ê³µì‹œì™€ ë¹„êµ ë¶„ì„"""
        comparison = {
            "comparison_available": False,
            "previous_filing_date": "",
            "key_changes": [],
            "key_changes_translated": [],
            "metric_changes": {},
            "metric_changes_translated": {},
            "new_risks": [],
            "removed_risks": [],
            "trend_analysis": "",
            "trend_analysis_translated": ""
        }
        
        try:
            # ìºì‹œì—ì„œ ì´ì „ ê³µì‹œ ì°¾ê¸° (ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ìºì‹œ)
            cache_key = f"{ticker}_{filing_type}_previous"
            if hasattr(self, 'filing_cache') and cache_key in self.filing_cache:
                previous_filing = self.filing_cache[cache_key]
                comparison["comparison_available"] = True
                comparison["previous_filing_date"] = previous_filing.get("filing_date", "")
                
                # ì´ì „ currentë¥¼ previousë¡œ ì´ë™
                self.filing_cache[cache_key] = previous_filing
                
                # í˜„ì¬ ê³µì‹œ ìºì‹œì— ì €ì¥
                current_cache_key = f"{ticker}_{filing_type}_current"
                self.filing_cache[current_cache_key] = current_filing
                
                # ì£¼ìš” ì§€í‘œ ë¹„êµ
                await self._compare_metrics(current_filing, previous_filing, comparison)
                
                # ë¦¬ìŠ¤í¬ ìš”ì¸ ë¹„êµ
                self._compare_risks(current_filing, previous_filing, comparison)
                
                # íŠ¸ë Œë“œ ë¶„ì„
                trend = await self._analyze_filing_trend(current_filing, previous_filing, filing_type)
                comparison["trend_analysis"] = trend
                comparison["trend_analysis_translated"] = await translate_text(trend, "ko")
                
            else:
                # ìºì‹œê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
                if not hasattr(self, 'filing_cache'):
                    self.filing_cache = {}
                
                # í˜„ì¬ ê³µì‹œë¥¼ currentë¡œ ì €ì¥ (ë‹¤ìŒì—ëŠ” previousê°€ ë¨)
                current_key = f"{ticker}_{filing_type}_current"
                if current_key in self.filing_cache:
                    # ê¸°ì¡´ currentë¥¼ previousë¡œ ì´ë™
                    self.filing_cache[cache_key] = self.filing_cache[current_key]
                
                # í˜„ì¬ ê³µì‹œë¥¼ ìºì‹œì— ì €ì¥
                self.filing_cache[current_key] = current_filing
                
        except Exception as e:
            logger.warning(f"ê³µì‹œ ë¹„êµ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        
        return comparison
    
    async def _compare_metrics(self, current: Dict[str, Any], previous: Dict[str, Any], 
                              comparison: Dict[str, Any]):
        """ì£¼ìš” ì§€í‘œ ë¹„êµ"""
        current_info = current.get("extracted_info", {})
        previous_info = previous.get("extracted_info", {})
        
        # ì¬ë¬´ ë°ì´í„° ë¹„êµ
        current_financial = current_info.get("financial_data", {})
        previous_financial = previous_info.get("financial_data", {})
        
        metrics_to_compare = ["revenue", "net_income", "total_assets"]
        
        for metric in metrics_to_compare:
            if metric in current_financial and metric in previous_financial:
                current_val = current_financial[metric]
                previous_val = previous_financial[metric]
                
                if previous_val != 0:
                    change_pct = ((current_val - previous_val) / previous_val) * 100
                    
                    change_desc_en = f"{metric}: {change_pct:+.1f}% change"
                    change_desc_ko = await translate_text(change_desc_en, "ko")
                    
                    comparison["metric_changes"][metric] = {
                        "current": current_val,
                        "previous": previous_val,
                        "change_percent": change_pct
                    }
                    comparison["metric_changes_translated"][metric] = change_desc_ko
                    
                    # ì¤‘ìš”í•œ ë³€í™” ì‹ë³„
                    if abs(change_pct) > 10:
                        significance = "significant increase" if change_pct > 0 else "significant decrease"
                        key_change_en = f"{metric} showed {significance} of {abs(change_pct):.1f}%"
                        key_change_ko = await translate_text(key_change_en, "ko")
                        
                        comparison["key_changes"].append(key_change_en)
                        comparison["key_changes_translated"].append(key_change_ko)
    
    def _compare_risks(self, current: Dict[str, Any], previous: Dict[str, Any], 
                      comparison: Dict[str, Any]):
        """ë¦¬ìŠ¤í¬ ìš”ì¸ ë¹„êµ"""
        current_info = current.get("extracted_info", {})
        previous_info = previous.get("extracted_info", {})
        
        current_risks = set(current_info.get("risks", []))
        previous_risks = set(previous_info.get("risks", []))
        
        # ìƒˆë¡œìš´ ë¦¬ìŠ¤í¬
        new_risks = current_risks - previous_risks
        if new_risks:
            comparison["new_risks"] = list(new_risks)
        
        # ì œê±°ëœ ë¦¬ìŠ¤í¬
        removed_risks = previous_risks - current_risks
        if removed_risks:
            comparison["removed_risks"] = list(removed_risks)
    
    async def _analyze_filing_trend(self, current: Dict[str, Any], previous: Dict[str, Any], 
                                   filing_type: str) -> str:
        """ê³µì‹œ íŠ¸ë Œë“œ ë¶„ì„"""
        trends = []
        
        # ë§¤ì¶œ íŠ¸ë Œë“œ
        current_revenue = current.get("extracted_info", {}).get("financial_data", {}).get("revenue", 0)
        previous_revenue = previous.get("extracted_info", {}).get("financial_data", {}).get("revenue", 0)
        
        if current_revenue and previous_revenue:
            revenue_growth = ((current_revenue - previous_revenue) / previous_revenue) * 100
            if revenue_growth > 5:
                trends.append("Revenue growth momentum continues")
            elif revenue_growth < -5:
                trends.append("Revenue decline needs attention")
            else:
                trends.append("Revenue remains stable")
        
        # ìˆ˜ìµì„± íŠ¸ë Œë“œ
        current_margin = current.get("extracted_info", {}).get("key_ratios", {}).get("net_margin")
        previous_margin = previous.get("extracted_info", {}).get("key_ratios", {}).get("net_margin")
        
        if current_margin and previous_margin:
            current_margin_val = float(current_margin.replace('%', ''))
            previous_margin_val = float(previous_margin.replace('%', ''))
            
            if current_margin_val > previous_margin_val:
                trends.append("Profitability improving")
            elif current_margin_val < previous_margin_val:
                trends.append("Margin pressure observed")
        
        # Form 4 ë‚´ë¶€ì ê±°ë˜ íŠ¸ë Œë“œ
        if filing_type == "4":
            current_sentiment = current.get("extracted_info", {}).get("insider_sentiment", "")
            if "Buy" in current_sentiment:
                trends.append("Insider confidence indicated by purchases")
            elif "Sell" in current_sentiment:
                trends.append("Insider selling activity noted")
        
        return ". ".join(trends) if trends else "No significant trends identified"
    
    def _extract_proxy_info(self, text: str) -> Dict[str, Any]:
        """DEF 14A ì£¼ì£¼ì´íšŒ ìœ„ì„ì¥ì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ"""
        info = {
            "executive_compensation": [],
            "proposals": []
        }
        
        # ì„ì› ë³´ìˆ˜ ì •ë³´
        comp_pattern = re.search(
            r"total\s+compensation.*?\$?([\d,]+(?:\.\d+)?)[\s]?(?:million)?",
            text, re.IGNORECASE
        )
        if comp_pattern:
            info["executive_compensation"].append(f"ì„ì› ì´ ë³´ìˆ˜: ${comp_pattern.group(1)}")
            
        # ì£¼ì£¼ ì œì•ˆ ì‚¬í•­
        if "proposal" in text.lower():
            info["proposals"].append("ì£¼ì£¼ ì œì•ˆ ì‚¬í•­ í¬í•¨")
            
        return info
    
    async def _get_cik_for_ticker(self, ticker: str) -> str:
        """í‹°ì»¤ì—ì„œ CIK(Central Index Key) ì¡°íšŒ"""
        # ìºì‹œ í™•ì¸
        if ticker.upper() in self.cik_cache:
            return self.cik_cache[ticker.upper()]
            
        try:
            # SECì˜ ê³µì‹ í‹°ì»¤-CIK ë§¤í•‘ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            url = "https://www.sec.gov/files/company_tickers.json"
            headers = {"User-Agent": self.user_agent}
            
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.get(url, headers=headers)
                
                if response.status_code == 200:
                    tickers_data = response.json()
                    
                    # ëª¨ë“  íšŒì‚¬ ì •ë³´ë¥¼ ìºì‹œì— ì €ì¥
                    for company_data in tickers_data.values():
                        company_ticker = company_data.get('ticker', '').upper()
                        cik = str(company_data.get('cik_str', '')).zfill(10)
                        if company_ticker:
                            self.cik_cache[company_ticker] = cik
                    
                    # ìš”ì²­ëœ í‹°ì»¤ì˜ CIK ë°˜í™˜
                    result = self.cik_cache.get(ticker.upper(), None)
                    if not result:
                        raise DataNotFoundError("CIK", ticker)
                    return result
                elif response.status_code == 429:
                    raise APIRateLimitError("SEC", 60)
                else:
                    logger.error(f"âŒ SEC í‹°ì»¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {response.status_code}")
                    return None
                    
        except Exception as e:
            print(f"âŒ CIK ì¡°íšŒ ì˜¤ë¥˜: {e}")
            # í´ë°±: ê¸°ë³¸ CIK ë§¤í•‘ ì‚¬ìš©
            fallback_map = {
                "AAPL": "0000320193",
                "TSLA": "0001318605",
                "NVDA": "0001045810",
                "GOOGL": "0001652044",
                "MSFT": "0000789019",
                "AMZN": "0001018724",
                "META": "0001326801",
                "PLTR": "0001321655"
            }
            return fallback_map.get(ticker.upper())
    
    async def _fetch_sec_filings(self, ticker: str) -> List[Dict]:
        """SEC EDGAR APIë¡œ ê³µì‹œ ê°€ì ¸ì˜¤ê¸°"""
        # ë”ë¯¸ ë°ì´í„° ì‚¬ìš© ëª¨ë“œì¸ ê²½ìš°
        if self.use_mock_data:
            logger.info(f"ğŸ­ ë”ë¯¸ ë°ì´í„° ëª¨ë“œ í™œì„±í™” - ëª¨ì˜ SEC ê³µì‹œ ë°˜í™˜")
            return self._get_mock_filings(ticker)
            
        try:
            # ë™ì  CIK ì¡°íšŒ
            cik = await self._get_cik_for_ticker(ticker)
            if not cik:
                logger.warning(f"âš ï¸ {ticker}ì˜ CIKë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return []  # ë¹ˆ ë°ì´í„° ë°˜í™˜
                
            # SEC EDGAR API í˜¸ì¶œ
            url = f"https://data.sec.gov/submissions/CIK{cik}.json"
            headers = {
                "User-Agent": self.user_agent,
                "Accept-Encoding": "gzip, deflate"
            }
            
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.get(url, headers=headers)
                
                if response.status_code == 200:
                    data = response.json()
                    recent_filings = data.get("filings", {}).get("recent", {})
                    
                    # ìµœê·¼ ê³µì‹œ í¬ë§·íŒ…
                    formatted_filings = []
                    forms = recent_filings.get("form", [])[:self.max_filings]
                    dates = recent_filings.get("filingDate", [])[:self.max_filings]
                    accessions = recent_filings.get("accessionNumber", [])[:self.max_filings]
                    
                    # ëª¨ë“  ë°°ì—´ì˜ ìµœì†Œ ê¸¸ì´ í™•ì¸
                    max_items = min(len(forms), len(dates), len(accessions), self.max_filings)
                    
                    for i in range(max_items):
                        # ê° ë°°ì—´ ìš”ì†Œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                        form_type = forms[i] if i < len(forms) else "Unknown"
                        filing_date = dates[i] if i < len(dates) else ""
                        accession_number = accessions[i] if i < len(accessions) else ""
                        
                        if not accession_number:
                            continue
                            
                        filing_url = f"https://www.sec.gov/Archives/edgar/data/{cik.lstrip('0')}/{accession_number.replace('-', '')}/{accession_number}.txt"
                        
                        # í¼ íƒ€ì…ë³„ ì„¤ëª… ì¶”ê°€
                        form_descriptions = {
                            "10-K": "ì—°ê°„ ë³´ê³ ì„œ - íšŒì‚¬ì˜ ì—°ê°„ ì‹¤ì  ë° ì¬ë¬´ìƒíƒœ",
                            "10-Q": "ë¶„ê¸° ë³´ê³ ì„œ - ë¶„ê¸°ë³„ ì‹¤ì  ë° ê²½ì˜ í˜„í™©",
                            "8-K": "ì„ì‹œ ë³´ê³ ì„œ - ì£¼ìš” ì´ë²¤íŠ¸ ë° ê²½ì˜ìƒ ì¤‘ìš” ë³€ê²½ì‚¬í•­",
                            "4": "ë‚´ë¶€ì ê±°ë˜ - ì„ì›ì§„ì˜ ì£¼ì‹ ë§¤ë§¤ ë‚´ì—­",
                            "DEF 14A": "ì£¼ì£¼ì´íšŒ ìœ„ì„ì¥ - ì£¼ì£¼ì´íšŒ ì•ˆê±´ ë° ì„ì› ë³´ìˆ˜",
                            "144": "ì œí•œ ì£¼ì‹ ë§¤ë„ ì‹ ê³  - ë‚´ë¶€ìì˜ ì£¼ì‹ ë§¤ë„ ê³„íš",
                            "S-8": "ì§ì› ì£¼ì‹ ì˜µì…˜ - ì§ì› ëŒ€ìƒ ì£¼ì‹ ë°œí–‰ ê³„íš",
                            "S-3": "ìœ ê°€ì¦ê¶Œ ì‹ ê³ ì„œ - ì‹ ê·œ ì¦ê¶Œ ë°œí–‰ ê³„íš"
                        }
                        
                        form_desc = form_descriptions.get(form_type, "ê¸°íƒ€ ê³µì‹œ")
                        
                        # SEC ê³µì‹œ ì œëª©ê³¼ ìš”ì•½ ìƒì„±
                        title = f"{ticker} {form_type} ê³µì‹œ ({filing_date})"
                        content = f"{form_desc}. ì´ ê³µì‹œëŠ” {ticker}ì˜ {form_type} ì–‘ì‹ìœ¼ë¡œ ì œì¶œëœ ê³µì‹ ë¬¸ì„œì…ë‹ˆë‹¤."
                        
                        # ê³µì‹œ ë¬¸ì„œì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ ì‹œë„
                        extracted_info = await self._extract_filing_content(filing_url, form_type)
                        
                        # ì¶”ì¶œëœ ì •ë³´ë¥¼ contentì— ì¶”ê°€ (ë²ˆì—­ëœ ë²„ì „ ìš°ì„  ì‚¬ìš©)
                        if extracted_info:
                            if extracted_info.get("key_metrics_translated"):
                                content += f" ì£¼ìš” ì§€í‘œ: {', '.join(extracted_info['key_metrics_translated'])}"
                            elif extracted_info.get("key_metrics"):
                                content += f" ì£¼ìš” ì§€í‘œ: {', '.join(extracted_info['key_metrics'])}"
                                
                            if extracted_info.get("quarterly_metrics"):
                                content += f" ë¶„ê¸° ì‹¤ì : {', '.join(extracted_info['quarterly_metrics'])}"
                                
                            if extracted_info.get("events"):
                                content += f" ì£¼ìš” ì´ë²¤íŠ¸: {', '.join(extracted_info['events'])}"
                                
                            if extracted_info.get("risks_translated"):
                                content += f" ë¦¬ìŠ¤í¬ ìš”ì¸: {', '.join(extracted_info['risks_translated'])}"
                            elif extracted_info.get("risks"):
                                content += f" ë¦¬ìŠ¤í¬ ìš”ì¸: {', '.join(extracted_info['risks'])}"
                                
                            if extracted_info.get("md&a_summary_translated"):
                                content += f" ê²½ì˜ì§„ ë¶„ì„: {extracted_info['md&a_summary_translated'][:200]}..."
                                
                            # Form 4 ë‚´ë¶€ì ê±°ë˜ ì •ë³´
                            if extracted_info.get("transaction_summary_translated"):
                                content += f" ë‚´ë¶€ì ê±°ë˜: {extracted_info['transaction_summary_translated']}"
                                if extracted_info.get("insider_sentiment_translated"):
                                    content += f" ({extracted_info['insider_sentiment_translated']})"
                            
                            # ì¬ë¬´ í…Œì´ë¸” ì •ë³´
                            if extracted_info.get("financial_highlights_translated"):
                                content += f" ì¬ë¬´ í•˜ì´ë¼ì´íŠ¸: {extracted_info['financial_highlights_translated']}"
                            elif extracted_info.get("financial_data_text_translated"):
                                content += f" ì¬ë¬´ ë°ì´í„°: {', '.join(extracted_info['financial_data_text_translated'][:3])}"
                        
                        filing_data = {
                            "form_type": form_type,
                            "title": title,
                            "content": content,
                            "description": form_desc,
                            "filing_date": filing_date,
                            "url": filing_url,
                            "source": "sec",
                            "sentiment": None,  # ë‚˜ì¤‘ì— ê°ì •ë¶„ì„ì—ì„œ ì±„ì›€
                            "extracted_info": extracted_info,  # ì¶”ì¶œëœ ìƒì„¸ ì •ë³´
                            "timestamp": datetime.now().isoformat(),  # ìˆ˜ì§‘ íƒ€ì„ìŠ¤íƒ¬í”„
                            "log_message": f"ğŸ“„ ê³µì‹œ: {form_type} - {filing_date}"
                        }
                        
                        # ë¹„êµ ë¶„ì„ ìˆ˜í–‰ (10-K, 10-Q, 4 í¼ì— ëŒ€í•´)
                        if form_type in ["10-K", "10-Q", "4"] and extracted_info:
                            comparison = await self._compare_filings(ticker, filing_data, form_type)
                            filing_data["comparison"] = comparison
                            
                            # ë¹„êµ ì •ë³´ë¥¼ contentì— ì¶”ê°€
                            if comparison.get("comparison_available") and comparison.get("key_changes_translated"):
                                content += f" ì´ì „ ëŒ€ë¹„ ì£¼ìš” ë³€í™”: {', '.join(comparison['key_changes_translated'][:2])}"
                                filing_data["content"] = content
                        
                        formatted_filings.append(filing_data)
                        
                    return formatted_filings
                elif response.status_code == 429:
                    raise APIRateLimitError("SEC", 60)
                else:
                    logger.error(f"âŒ SEC API ì˜¤ë¥˜: {response.status_code}")
                    return []  # ë¹ˆ ë°ì´í„° ë°˜í™˜
                    
        except (APIRateLimitError, DataNotFoundError):
            raise  # ì»¤ìŠ¤í…€ ì—ëŸ¬ëŠ” ë‹¤ì‹œ ë°œìƒì‹œí‚´
        except httpx.TimeoutException:
            raise APITimeoutError("SEC", self.timeout)
        except Exception as e:
            logger.error(f"âŒ SEC API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return []  # ë¹ˆ ë°ì´í„° ë°˜í™˜
            
    def _get_mock_filings(self, ticker: str) -> List[Dict]:
        """ëª¨ì˜ ê³µì‹œ ë°ì´í„° ìƒì„± - í‹°ì»¤ë³„ë¡œ ë‹¤ë¥¸ ë‚´ìš©"""
        today = datetime.now()
        
        # í‹°ì»¤ë³„ íŠ¹í™”ëœ ê³µì‹œ ë°ì´í„°
        ticker_specific_filings = {
            "AAPL": [
                {
                    "form_type": "10-K",
                    "title": "Annual Report - 2024 íšŒê³„ì—°ë„ ë§¤ì¶œ 4,000ì–µ ë‹¬ëŸ¬ ëŒíŒŒ",
                    "filing_date": (today - timedelta(days=30)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/10K-2024",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ì• í”Œ ì—°ê°„ ë§¤ì¶œ ì‚¬ìƒ ìµœëŒ€ ê¸°ë¡. ì„œë¹„ìŠ¤ ë¶€ë¬¸ ì„±ì¥ì´ ê²¬ì¸",
                    "log_message": "ğŸ“„ ê³µì‹œ: 10-K - ì—°ê°„ ë§¤ì¶œ ìµœëŒ€ ê¸°ë¡"
                },
                {
                    "form_type": "10-Q",
                    "title": "Quarterly Report - Q3 2024 ì•„ì´í° íŒë§¤ ë‘”í™”",
                    "filing_date": (today - timedelta(days=10)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/10Q-Q3-2024",
                    "source": "sec",
                    "sentiment": None,
                    "content": "3ë¶„ê¸° ì•„ì´í° íŒë§¤ëŸ‰ ì „ë…„ ëŒ€ë¹„ 5% ê°ì†Œ. ì¤‘êµ­ ì‹œì¥ ë¶€ì§„",
                    "log_message": "ğŸ“„ ê³µì‹œ: 10-Q - ì•„ì´í° íŒë§¤ ë‘”í™”"
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - ìì‚¬ì£¼ 900ì–µ ë‹¬ëŸ¬ ë§¤ì… ë°œí‘œ",
                    "filing_date": (today - timedelta(days=2)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-buyback",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ì• í”Œ ì´ì‚¬íšŒ, 900ì–µ ë‹¬ëŸ¬ ê·œëª¨ ìì‚¬ì£¼ ë§¤ì… í”„ë¡œê·¸ë¨ ìŠ¹ì¸",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - ëŒ€ê·œëª¨ ìì‚¬ì£¼ ë§¤ì…"
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - AI ì—°êµ¬ê°œë°œ íˆ¬ì í™•ëŒ€",
                    "filing_date": (today - timedelta(days=5)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-ai",
                    "source": "sec",
                    "sentiment": None,
                    "content": "AI ë° ë¨¸ì‹ ëŸ¬ë‹ ì—°êµ¬ê°œë°œì— 50ì–µ ë‹¬ëŸ¬ ì¶”ê°€ íˆ¬ì ê³„íš",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - AI R&D íˆ¬ì"
                },
                {
                    "form_type": "DEF 14A",
                    "title": "Proxy Statement - ì„ì› ë³´ìˆ˜ 15% ì¸ìƒ",
                    "filing_date": (today - timedelta(days=15)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/DEF14A",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ì£¼ì£¼ì´íšŒ ì•ˆê±´: CEO ë° ì£¼ìš” ì„ì› ë³´ìˆ˜ ì¸ìƒì•ˆ",
                    "log_message": "ğŸ“„ ê³µì‹œ: DEF 14A - ì„ì› ë³´ìˆ˜"
                },
                {
                    "form_type": "4",
                    "title": "Form 4 - Tim Cook CEO ì£¼ì‹ 50ë§Œì£¼ ë§¤ë„",
                    "filing_date": (today - timedelta(days=3)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/Form4-cook",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ë‚´ë¶€ì ê±°ë˜: Tim Cook (CEO) 50ë§Œì£¼ ë§¤ë„ @ $195.50. ì„¸ê¸ˆ ë‚©ë¶€ ëª©ì . ì”ì—¬ ë³´ìœ : 330ë§Œì£¼ (ë³´í†µ ë§¤ë„ ì‹ í˜¸)",
                    "log_message": "ğŸ“„ ê³µì‹œ: Form 4 - CEO ì£¼ì‹ ë§¤ë„"
                }
            ],
            "TSLA": [
                {
                    "form_type": "10-K",
                    "title": "Annual Report - 2024 ì°¨ëŸ‰ ì¸ë„ëŸ‰ 180ë§ŒëŒ€ ë‹¬ì„±",
                    "filing_date": (today - timedelta(days=30)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/10K-2024",
                    "source": "sec",
                    "sentiment": None,
                    "content": "í…ŒìŠ¬ë¼ ì—°ê°„ ì°¨ëŸ‰ ì¸ë„ëŸ‰ 180ë§ŒëŒ€ë¡œ ì „ë…„ ëŒ€ë¹„ 35% ì„±ì¥",
                    "log_message": "ğŸ“„ ê³µì‹œ: 10-K - ì°¨ëŸ‰ ì¸ë„ëŸ‰ ì‹ ê¸°ë¡"
                },
                {
                    "form_type": "10-Q",
                    "title": "Quarterly Report - Q3 2024 ì˜ì—…ì´ìµë¥  9.6%",
                    "filing_date": (today - timedelta(days=10)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/10Q-Q3-2024",
                    "source": "sec",
                    "sentiment": None,
                    "content": "3ë¶„ê¸° ì˜ì—…ì´ìµë¥  ê°œì„ . ì œì¡° íš¨ìœ¨ì„± í–¥ìƒ íš¨ê³¼",
                    "log_message": "ğŸ“„ ê³µì‹œ: 10-Q - ìˆ˜ìµì„± ê°œì„ "
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - ë©•ì‹œì½” ê¸°ê°€íŒ©í† ë¦¬ ê±´ì„¤ ì°©ìˆ˜",
                    "filing_date": (today - timedelta(days=2)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-mexico",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ë©•ì‹œì½” ê¸°ê°€íŒ©í† ë¦¬ ê±´ì„¤ ê³µì‹ ì°©ìˆ˜. 100ì–µ ë‹¬ëŸ¬ íˆ¬ì",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - ë©•ì‹œì½” ê³µì¥"
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - FSD v12 ë² íƒ€ ì¶œì‹œ",
                    "filing_date": (today - timedelta(days=7)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-fsd",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ì™„ì „ììœ¨ì£¼í–‰(FSD) v12 ë² íƒ€ ë²„ì „ ë¶ë¯¸ ì‹œì¥ ì¶œì‹œ",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - FSD ì—…ë°ì´íŠ¸"
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - ì—ë„ˆì§€ ì‚¬ì—…ë¶€ ë¶„ì‚¬ ê²€í† ",
                    "filing_date": (today - timedelta(days=20)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-energy",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ì—ë„ˆì§€ ì €ì¥ì¥ì¹˜ ì‚¬ì—…ë¶€ ë¶„ì‚¬ ê°€ëŠ¥ì„± ê²€í†  ì¤‘",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - ì‚¬ì—…ë¶€ ë¶„ì‚¬"
                },
                {
                    "form_type": "4",
                    "title": "Form 4 - Elon Musk ì£¼ì‹ 200ë§Œì£¼ ë§¤ìˆ˜",
                    "filing_date": (today - timedelta(days=1)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/Form4-musk",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ë‚´ë¶€ì ê±°ë˜: Elon Musk (CEO) 200ë§Œì£¼ ë§¤ìˆ˜ @ $175.25. ê³µê°œì‹œì¥ ë§¤ìˆ˜. ì´ ë³´ìœ : 4ì–µ 1,200ë§Œì£¼ (20.6%) (ê°•ë ¥í•œ ë§¤ìˆ˜ ì‹ í˜¸)",
                    "log_message": "ğŸ“„ ê³µì‹œ: Form 4 - CEO ëŒ€ëŸ‰ ë§¤ìˆ˜"
                }
            ],
            "NVDA": [
                {
                    "form_type": "10-K",
                    "title": "Annual Report - 2024 ë°ì´í„°ì„¼í„° ë§¤ì¶œ 600% ì„±ì¥",
                    "filing_date": (today - timedelta(days=30)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/10K-2024",
                    "source": "sec",
                    "sentiment": None,
                    "content": "AI ë¶ìœ¼ë¡œ ë°ì´í„°ì„¼í„° ë¶€ë¬¸ ë§¤ì¶œ ì „ë…„ ëŒ€ë¹„ 600% ê¸‰ì¦",
                    "log_message": "ğŸ“„ ê³µì‹œ: 10-K - ë°ì´í„°ì„¼í„° ë§¤ì¶œ ê¸‰ì¦"
                },
                {
                    "form_type": "10-Q",
                    "title": "Quarterly Report - Q3 2024 ë§¤ì¶œ 181ì–µ ë‹¬ëŸ¬",
                    "filing_date": (today - timedelta(days=10)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/10Q-Q3-2024",
                    "source": "sec",
                    "sentiment": None,
                    "content": "3ë¶„ê¸° ë§¤ì¶œ ì‹œì¥ ì˜ˆìƒì¹˜ 20% ìƒíšŒ. H100 ìˆ˜ìš” ì§€ì†",
                    "log_message": "ğŸ“„ ê³µì‹œ: 10-Q - ì‹¤ì  ì„œí”„ë¼ì´ì¦ˆ"
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - H200 ì¹© ëŒ€ëŸ‰ ìƒì‚° ì‹œì‘",
                    "filing_date": (today - timedelta(days=2)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-h200",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ì°¨ì„¸ëŒ€ AI ì¹© H200 ëŒ€ëŸ‰ ìƒì‚° ëŒì…. ì„±ëŠ¥ 70% í–¥ìƒ",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - H200 ìƒì‚°"
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - ì¤‘êµ­ ìˆ˜ì¶œ ì œí•œ ëŒ€ì‘ ê³„íš",
                    "filing_date": (today - timedelta(days=8)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-china",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ì¤‘êµ­ ì‹œì¥ìš© ê·œì œ ì¤€ìˆ˜ ì¹© ê°œë°œ. ì„±ëŠ¥ ì œí•œ ë²„ì „ ì¶œì‹œ",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - ì¤‘êµ­ ëŒ€ì‘"
                },
                {
                    "form_type": "8-K",
                    "title": "Current Report - ARM ì¸ìˆ˜ ì² íšŒ í›„ íŒŒíŠ¸ë„ˆì‹­",
                    "filing_date": (today - timedelta(days=25)).strftime("%Y-%m-%d"),
                    "url": f"https://sec.gov/example/{ticker}/8K-arm",
                    "source": "sec",
                    "sentiment": None,
                    "content": "ARMê³¼ 20ë…„ ë¼ì´ì„ ìŠ¤ ê³„ì•½ ì²´ê²°. CPU ì„¤ê³„ í˜‘ë ¥ ê°•í™”",
                    "log_message": "ğŸ“„ ê³µì‹œ: 8-K - ARM íŒŒíŠ¸ë„ˆì‹­"
                }
            ]
        }
        
        # ê¸°ë³¸ ê³µì‹œ í…œí”Œë¦¿
        default_filings = [
            {
                "form_type": "10-K",
                "title": "Annual Report",
                "filing_date": (today - timedelta(days=30)).strftime("%Y-%m-%d"),
                "url": f"https://sec.gov/example/{ticker}/10K",
                "source": "sec",
                "sentiment": None,
                "content": "ì—°ê°„ ë³´ê³ ì„œ",
                "log_message": "ğŸ“„ ê³µì‹œ: 10-K - Annual Report"
            },
            {
                "form_type": "10-Q",
                "title": "Quarterly Report",
                "filing_date": (today - timedelta(days=10)).strftime("%Y-%m-%d"),
                "url": f"https://sec.gov/example/{ticker}/10Q",
                "source": "sec",
                "sentiment": None,
                "content": "ë¶„ê¸° ë³´ê³ ì„œ",
                "log_message": "ğŸ“„ ê³µì‹œ: 10-Q - Quarterly Report"
            },
            {
                "form_type": "8-K",
                "title": "Current Report",
                "filing_date": (today - timedelta(days=2)).strftime("%Y-%m-%d"),
                "url": f"https://sec.gov/example/{ticker}/8K",
                "source": "sec",
                "sentiment": None,
                "content": "ì„ì‹œ ë³´ê³ ì„œ",
                "log_message": "ğŸ“„ ê³µì‹œ: 8-K - Current Report"
            }
        ]
        
        # í‹°ì»¤ì— ë§ëŠ” ê³µì‹œ ì„ íƒ
        filings_template = ticker_specific_filings.get(ticker, default_filings)
        
        return filings_template[:self.max_filings]
    
    def _setup_http_endpoints(self):
        """HTTP ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •"""
        @self.app.post("/collect_sec_data", dependencies=[Depends(verify_api_key)])
        async def collect_sec_data(request: SECRequest):
            """HTTPë¥¼ í†µí•œ SEC ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘"""
            try:
                print(f"ğŸ“„ HTTP ìš”ì²­ìœ¼ë¡œ SEC ê³µì‹œ ìˆ˜ì§‘: {request.ticker}")
                
                # SEC ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘
                filings_data = await self._fetch_sec_filings(request.ticker)
                
                result = {
                    "data": filings_data,
                    "count": len(filings_data),
                    "source": "sec",
                    "log_message": f"âœ… {request.ticker} ê³µì‹œ {len(filings_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ"
                }
                
                # ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ì´ë²¤íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸
                await self.broadcast_event(
                    event_type="data_collected",
                    event_data={
                        "source": "sec",
                        "ticker": request.ticker,
                        "count": len(filings_data)
                    }
                )
                
                return result
                
            except Exception as e:
                print(f"âŒ HTTP SEC ê³µì‹œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
                return {
                    "error": str(e),
                    "data": [],
                    "count": 0,
                    "source": "sec"
                }


# ëª¨ë“ˆ ë ˆë²¨ì—ì„œ ì—ì´ì „íŠ¸ì™€ app ìƒì„±
agent = SECAgentV2()
app = agent.app

@app.on_event("startup")
async def startup():
    await agent.start()

@app.on_event("shutdown")
async def shutdown():
    await agent.stop()

# ë…ë¦½ ì‹¤í–‰ìš©
if __name__ == "__main__":
    agent.run()