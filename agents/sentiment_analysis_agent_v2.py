#!/usr/bin/env python3
"""
Sentiment Analysis Agent V2 - A2A í”„ë¡œí† ì½œ ê¸°ë°˜ ê°ì • ë¶„ì„ ì—ì´ì „íŠ¸
ì„¤ì • ê°€ëŠ¥í•œ LLMì„ ì‚¬ìš©í•˜ì—¬ ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import os
import sys
import asyncio
import httpx
import json
import re
import logging
from typing import Dict, Any, List
from datetime import datetime
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from a2a_core.base.base_agent import BaseAgent
from a2a_core.protocols.message import A2AMessage, MessageType
from fastapi import FastAPI
from pydantic import BaseModel
from fastapi import Depends
import uvicorn
from utils.llm_manager import get_llm_manager

# ì„¤ì • ê´€ë¦¬ì ë° ì»¤ìŠ¤í…€ ì—ëŸ¬ ì„í¬íŠ¸
from utils.config_manager import config
from utils.errors import LLMResponseError, LLMQuotaExceededError, SentimentAnalysisError
from utils.auth import verify_api_key
from utils.cache_manager import cache_manager

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(override=True)

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

class SentimentRequest(BaseModel):
    ticker: str
    data: Dict[str, List[Dict[str, Any]]]

class SentimentAnalysisAgentV2(BaseAgent):
    """ê°ì • ë¶„ì„ A2A ì—ì´ì „íŠ¸"""
    
    def __init__(self, name: str = None, port: int = None):
        # ì„¤ì •ì—ì„œ ì—ì´ì „íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        agent_config = config.get_agent_config("sentiment_analysis")
        
        super().__init__(
            name=name or agent_config.get("name", "Sentiment Analysis Agent V2"),
            port=port or agent_config.get("port", 8202),
            description="ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” A2A ì—ì´ì „íŠ¸"
        )
        
        # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        self.timeout = agent_config.get("timeout", 120)
        self.batch_size = agent_config.get("batch_size", 10)
        
        # LLM Manager ì´ˆê¸°í™”
        self.llm_manager = get_llm_manager()
        available_providers = self.llm_manager.get_available_providers()
        logger.info(f"ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì œê³µì: {available_providers}")
        
        # ì²« ë²ˆì§¸ í”„ë¡œë°”ì´ë” ëª¨ë¸ ì •ë³´ í‘œì‹œ
        if available_providers:
            for provider in self.llm_manager.providers:
                if provider.is_available():
                    provider_name = provider.__class__.__name__
                    if hasattr(provider, 'model'):
                        logger.info(f"ğŸš€ ê¸°ë³¸ LLM ëª¨ë¸: {provider_name} ({provider.model})")
                    else:
                        logger.info(f"ğŸš€ ê¸°ë³¸ LLM ëª¨ë¸: {provider_name}")
                    break
        
        # Gemini API (ë ˆê±°ì‹œ - ì§ì ‘ API í˜¸ì¶œì´ í•„ìš”í•œ ê²½ìš°)
        self.gemini_api_key = config.get_env("GEMINI_API_KEY")
        self.gemini_api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={self.gemini_api_key}"
        
        # HTTP ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
        self._setup_http_endpoints()
        
    def _setup_http_endpoints(self):
        """HTTP ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •"""
        @self.app.post("/analyze_sentiment", dependencies=[Depends(verify_api_key)])
        async def analyze_sentiment(request: SentimentRequest):
            """HTTP ì—”ë“œí¬ì¸íŠ¸ë¡œ ê°ì • ë¶„ì„"""
            ticker = request.ticker
            data = request.data
            
            print(f"ğŸ¯ HTTP ìš”ì²­ìœ¼ë¡œ ê°ì • ë¶„ì„: {ticker}")
            
            # ìºì‹œ í‚¤ ìƒì„±ì„ ìœ„í•œ ë°ì´í„° í•´ì‹œ
            import hashlib
            data_hash = hashlib.md5(json.dumps(data, sort_keys=True).encode()).hexdigest()[:8]
            cache_params = {"ticker": ticker, "data_hash": data_hash}
            
            # ìºì‹œ í™•ì¸
            cached_result = await cache_manager.get_async("sentiment_analysis", cache_params)
            if cached_result:
                print(f"ğŸ’¾ ìºì‹œì—ì„œ ê°ì • ë¶„ì„ ê²°ê³¼ ë°˜í™˜")
                return cached_result
            
            # ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
            all_data = []
            for source, items in data.items():
                for item in items:
                    item["source"] = source
                    all_data.append(item)
            
            # ê°ì • ë¶„ì„ ìˆ˜í–‰
            result = await self._perform_sentiment_analysis(ticker, data)
            
            # ì„±ê³µí•œ ê²½ìš° ìºì‹œì— ì €ì¥
            if result.get("success_count", 0) > 0:
                await cache_manager.set_async("sentiment_analysis", cache_params, result)
            
            return result
        
    async def on_start(self):
        """ì—ì´ì „íŠ¸ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
        await self.register_capability({
            "name": "sentiment_analysis",
            "version": "2.0",
            "description": "ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ë°ì´í„°ë¥¼ ê°ì • ë¶„ì„",
            "input_schema": {
                "type": "object",
                "properties": {
                    "ticker": {"type": "string"},
                    "data": {"type": "object"}
                },
                "required": ["ticker", "data"]
            },
            "output_schema": {
                "type": "object",
                "properties": {
                    "analyzed_results": {"type": "array"},
                    "success_count": {"type": "number"},
                    "failure_count": {"type": "number"}
                }
            }
        })
        
    async def on_stop(self):
        """ì—ì´ì „íŠ¸ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
        pass
        
    async def handle_message(self, message: A2AMessage) -> None:
        """A2A ë©”ì‹œì§€ ì²˜ë¦¬"""
        print(f"ğŸ” ë©”ì‹œì§€ ìˆ˜ì‹  - Type: {message.header.message_type}, Action: {message.body.get('action')}")
        
        if message.header.message_type != MessageType.REQUEST:
            return
            
        body = message.body
        action = body.get("action")
        
        if action == "analyze_sentiment":
            payload = body.get("payload", {})
            ticker = payload.get("ticker")
            data = payload.get("data", {})
            
            print(f"ğŸ“Š ê°ì • ë¶„ì„ ì‹œì‘ - í‹°ì»¤: {ticker}")
            print(f"ğŸ“Š ë¶„ì„í•  ë°ì´í„° ì†ŒìŠ¤: {list(data.keys())}")
            
            try:
                # ì§ì ‘ ê°ì • ë¶„ì„ ìˆ˜í–‰
                result = await self._perform_sentiment_analysis(ticker, data)
                
                # ì„±ê³µ ì‘ë‹µ
                print(f"ğŸ“¤ ì‘ë‹µ ì „ì†¡ ì‹œë„ - Sender ID: {message.header.sender_id}")
                await self.reply_to_message(message, result, success=True)
                print(f"âœ… ê°ì • ë¶„ì„ ì™„ë£Œ ë° ì‘ë‹µ ì „ì†¡: {result.get('success_count', 0)}ê°œ ì„±ê³µ")
                        
            except Exception as e:
                print(f"âŒ ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
                
                await self.reply_to_message(
                    message, 
                    {"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}"}, 
                    success=False
                )
        else:
            await self.reply_to_message(
                message, 
                {"error": f"ì•Œ ìˆ˜ ì—†ëŠ” ì•¡ì…˜: {action}"}, 
                success=False
            )
            
    async def _perform_sentiment_analysis(self, ticker: str, data: dict) -> dict:
        """ê°ì • ë¶„ì„ ì§ì ‘ ìˆ˜í–‰"""
        print(f"ğŸ” ê°ì • ë¶„ì„ ì‹œì‘ - Ticker: {ticker}")
        print(f"ğŸ“Š ë°›ì€ ë°ì´í„° êµ¬ì¡°: {list(data.keys())}")
        
        if not self.gemini_api_key:
            print("âŒ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            return {
                "analyzed_results": [],
                "success_count": 0,
                "failure_count": 1,
                "error": "GEMINI_API_KEY not configured"
            }
            
        analyzed_results = []
        
        # ê° ì†ŒìŠ¤ë³„ ë°ì´í„° ì²˜ë¦¬
        for source, items in data.items():
            print(f"ğŸ” ì†ŒìŠ¤ '{source}' ì²˜ë¦¬ ì¤‘...")
            print(f"   - íƒ€ì…: {type(items)}")
            print(f"   - ë‚´ìš©: {items if not isinstance(items, list) else f'{len(items)}ê°œ í•­ëª©'}")
            
            if not isinstance(items, list):
                print(f"   âš ï¸ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜, ê±´ë„ˆëœ€")
                continue
                
            print(f"ğŸ“Š {source} ì†ŒìŠ¤ ë¶„ì„ ì¤‘: {len(items)}ê°œ í•­ëª©")
                
            for idx, item in enumerate(items):
                print(f"   ğŸ“ í•­ëª© {idx+1} ì²˜ë¦¬ ì¤‘...")
                if isinstance(item, dict):
                    print(f"      - í•­ëª© í‚¤: {list(item.keys())}")
                    # í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ
                    text_content = ""
                    if "title" in item and item["title"]:
                        text_content += item["title"]
                        print(f"      - title ì¶”ê°€: {item['title'][:30]}...")
                    if "content" in item and item["content"]:
                        text_content += " " + item["content"]
                        print(f"      - content ì¶”ê°€: {item['content'][:30]}...")
                    if "text" in item and item["text"]:
                        text_content += " " + item["text"]
                        print(f"      - text ì¶”ê°€: {item['text'][:30]}...")
                    
                    print(f"      - ìµœì¢… í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text_content)}")
                    
                    if not text_content.strip():
                        print("      âš ï¸ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ, ê±´ë„ˆëœ€")
                        continue
                        
                    try:
                        print("      ğŸš€ Gemini API í˜¸ì¶œ ì‹œì‘...")
                        # Gemini API í˜¸ì¶œ
                        sentiment_result = await self._analyze_with_llm(text_content, source, item)
                        analyzed_results.append(sentiment_result)
                        print(f"      âœ… ë¶„ì„ ì™„ë£Œ: {sentiment_result.get('summary', '')[:50]}...")
                        print(f"      ğŸ“Š ì ìˆ˜: {sentiment_result.get('score', 'N/A')}")
                    except Exception as e:
                        print(f"      âŒ í•­ëª© ë¶„ì„ ì‹¤íŒ¨: {e}")
                        import traceback
                        traceback.print_exc()
                        analyzed_results.append({
                            "text": text_content[:100] + "..." if len(text_content) > 100 else text_content,
                            "source": source,
                            "summary": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
                            "score": None,
                            "error": str(e)
                        })
        
        success_count = sum(1 for r in analyzed_results if r.get("score") is not None)
        failure_count = len(analyzed_results) - success_count
        
        return {
            "analyzed_results": analyzed_results,
            "success_count": success_count,
            "failure_count": failure_count,
            "log_message": f"âœ… {success_count}ê°œ í•­ëª© ê°ì • ë¶„ì„ ì™„ë£Œ"
        }
        
    async def _analyze_with_llm(self, text: str, source: str, original_item: dict = None) -> dict:
        """ì„¤ì •ëœ LLMì„ ì‚¬ìš©í•œ ê³ ê¸‰ ê¸ˆìœµ ê°ì • ë¶„ì„"""
        # í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œë°”ì´ë” í™•ì¸
        available_providers = self.llm_manager.get_available_providers()
        current_provider = available_providers[0] if available_providers else "unknown"
        print(f"         ğŸ”® {current_provider.upper()} ë¶„ì„ ì‹œì‘ - Source: {source}")
        print(f"         ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}")
        
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸° (LLM í† í° ì œí•œ ê³ ë ¤)
        max_text_length = 3000  # ì•½ 1000 í† í° ì •ë„
        if len(text) > max_text_length:
            text = text[:max_text_length] + "... (í…ìŠ¤íŠ¸ê°€ ì˜ë ¸ìŠµë‹ˆë‹¤)"
            print(f"         âœ‚ï¸ í…ìŠ¤íŠ¸ë¥¼ {max_text_length}ìë¡œ ì˜ëìŠµë‹ˆë‹¤")
        
        # ì†ŒìŠ¤ë³„ ì „ë¬¸ì ì¸ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        if source == "sec":
            context = "SEC ê³µì‹œ ìë£Œë¥¼ ê¸ˆìœµ ì „ë¬¸ê°€ ê´€ì ì—ì„œ"
            focus = "ì¬ë¬´ ì‹¤ì , ë¦¬ìŠ¤í¬ ìš”ì¸, ê²½ì˜ì§„ ì „ë§"
        elif source == "news":
            context = "ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ íˆ¬ì ë¶„ì„ê°€ ê´€ì ì—ì„œ"
            focus = "ì‹œì¥ ë°˜ì‘, ì—…ê³„ ë™í–¥, ê²½ìŸì‚¬ ëŒ€ë¹„"
        elif source == "twitter":
            context = "ì†Œì…œ ë¯¸ë””ì–´ ì—¬ë¡ ì„ ì‹œì¥ ì‹¬ë¦¬ ê´€ì ì—ì„œ"
            focus = "íˆ¬ìì ì •ì„œ, íŠ¸ë Œë“œ, ë°”ì´ëŸ´ ìš”ì†Œ"
        else:
            context = "íˆ¬ì ê´€ë ¨ í…ìŠ¤íŠ¸ë¥¼ ì „ë¬¸ê°€ ê´€ì ì—ì„œ"
            focus = "íˆ¬ì ê°€ì¹˜, ì„±ì¥ì„±, ë¦¬ìŠ¤í¬"
        
        prompt = f"""ê¸ˆìœµ ì „ë¬¸ê°€ë¡œì„œ {source} ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

í…ìŠ¤íŠ¸: "{text}"

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”:
{{
    "summary": "í•œì¤„ ìš”ì•½",
    "score": -1.0~1.0 ì‚¬ì´ ìˆ«ì,
    "confidence": 0.0~1.0 ì‚¬ì´ ìˆ«ì,
    "financial_impact": "high ë˜ëŠ” medium ë˜ëŠ” low",
    "key_topics": ["ì£¼ì œ1", "ì£¼ì œ2"],
    "risk_factors": ["ë¦¬ìŠ¤í¬1"],
    "opportunities": ["ê¸°íšŒ1"],
    "time_horizon": "short ë˜ëŠ” medium ë˜ëŠ” long"
}}"""
        
        try:
            # LLM Managerë¥¼ í†µí•´ ìƒì„±
            print(f"         ğŸ“¤ {current_provider} ìš”ì²­ ì „ì†¡ ì¤‘...")
            response = await self.llm_manager.generate(prompt)
            print(f"         ğŸ“¥ ì‘ë‹µ ìˆ˜ì‹ ")
            
            # JSON ì¶”ì¶œ
            match = re.search(r'\{.*\}', response, re.DOTALL)
            if match:
                try:
                    sentiment_data = json.loads(match.group(0))
                    # ì›ë³¸ ë°ì´í„°ì˜ ëª¨ë“  í•„ë“œë¥¼ ë³´ì¡´í•˜ë©´ì„œ ê°ì • ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                    result = original_item.copy() if original_item else {"text": text}
                    # scoreì™€ confidence ì•ˆì „í•˜ê²Œ ë³€í™˜
                    score_value = sentiment_data.get("score", 0)
                    if score_value is None:
                        score_value = 0
                    confidence_value = sentiment_data.get("confidence", 0.5)
                    if confidence_value is None:
                        confidence_value = 0.5
                        
                    result.update({
                        "source": source,
                        "summary": sentiment_data.get("summary", "ìš”ì•½ ì—†ìŒ"),
                        "score": float(score_value),
                        "confidence": float(confidence_value),
                        "financial_impact": sentiment_data.get("financial_impact", "medium"),
                        "key_topics": sentiment_data.get("key_topics", []),
                        "risk_factors": sentiment_data.get("risk_factors", []),
                        "opportunities": sentiment_data.get("opportunities", []),
                        "time_horizon": sentiment_data.get("time_horizon", "medium")
                    })
                    return result
                except json.JSONDecodeError as e:
                    print(f"         âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                    print(f"         ğŸ“„ ì›ë³¸ ë‚´ìš©: {response[:200]}...")
                    # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
                    logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ê°’ìœ¼ë¡œ ì²˜ë¦¬: {source}")
                    
        except LLMQuotaExceededError:
            raise  # í• ë‹¹ëŸ‰ ì´ˆê³¼ëŠ” ë‹¤ì‹œ ë°œìƒì‹œí‚´
        except Exception as e:
            logger.error(f"         âŒ LLM ì˜¤ë¥˜: {e}")
            raise LLMResponseError(current_provider, "JSON format")
        
        # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ Gemini API ì‚¬ìš© (í´ë°±)
        if current_provider != 'gemini' and self.gemini_api_key:
            print(f"         ğŸ”„ Gemini APIë¡œ í´ë°±...")
            return await self._analyze_with_gemini(text, source, original_item)
            
        # ìµœì¢… ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        result = original_item.copy() if original_item else {}
        result.update({
            "text": text[:200] + "..." if len(text) > 200 else text,
            "source": source,
            "summary": "ë¶„ì„ ì‹¤íŒ¨",
            "score": 0.0
        })
        return result
        
    async def _analyze_with_gemini(self, text: str, source: str, original_item: dict = None) -> dict:
        """Gemini APIë¥¼ ì§ì ‘ ì‚¬ìš©í•œ ê³ ê¸‰ ê¸ˆìœµ ê°ì • ë¶„ì„ (ë ˆê±°ì‹œ/í´ë°±)"""
        print(f"         ğŸ”® Gemini API ì§ì ‘ í˜¸ì¶œ - Source: {source}")
        print(f"         ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}")
        
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸° (LLM í† í° ì œí•œ ê³ ë ¤)
        max_text_length = 3000  # ì•½ 1000 í† í° ì •ë„
        if len(text) > max_text_length:
            text = text[:max_text_length] + "... (í…ìŠ¤íŠ¸ê°€ ì˜ë ¸ìŠµë‹ˆë‹¤)"
            print(f"         âœ‚ï¸ í…ìŠ¤íŠ¸ë¥¼ {max_text_length}ìë¡œ ì˜ëìŠµë‹ˆë‹¤")
        
        # ì†ŒìŠ¤ë³„ ì „ë¬¸ì ì¸ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        if source == "sec":
            context = "SEC ê³µì‹œ ìë£Œë¥¼ ê¸ˆìœµ ì „ë¬¸ê°€ ê´€ì ì—ì„œ"
            focus = "ì¬ë¬´ ì‹¤ì , ë¦¬ìŠ¤í¬ ìš”ì¸, ê²½ì˜ì§„ ì „ë§"
        elif source == "news":
            context = "ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ íˆ¬ì ë¶„ì„ê°€ ê´€ì ì—ì„œ"
            focus = "ì‹œì¥ ë°˜ì‘, ì—…ê³„ ë™í–¥, ê²½ìŸì‚¬ ëŒ€ë¹„"
        elif source == "twitter":
            context = "ì†Œì…œ ë¯¸ë””ì–´ ì—¬ë¡ ì„ ì‹œì¥ ì‹¬ë¦¬ ê´€ì ì—ì„œ"
            focus = "íˆ¬ìì ì •ì„œ, íŠ¸ë Œë“œ, ë°”ì´ëŸ´ ìš”ì†Œ"
        else:
            context = "íˆ¬ì ê´€ë ¨ í…ìŠ¤íŠ¸ë¥¼ ì „ë¬¸ê°€ ê´€ì ì—ì„œ"
            focus = "íˆ¬ì ê°€ì¹˜, ì„±ì¥ì„±, ë¦¬ìŠ¤í¬"
        
        prompt = f"""ê¸ˆìœµ ì „ë¬¸ê°€ë¡œì„œ {source} ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

í…ìŠ¤íŠ¸: "{text}"

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”:
{{
    "summary": "í•œì¤„ ìš”ì•½",
    "score": -1.0~1.0 ì‚¬ì´ ìˆ«ì,
    "confidence": 0.0~1.0 ì‚¬ì´ ìˆ«ì,
    "financial_impact": "high ë˜ëŠ” medium ë˜ëŠ” low",
    "key_topics": ["ì£¼ì œ1", "ì£¼ì œ2"],
    "risk_factors": ["ë¦¬ìŠ¤í¬1"],
    "opportunities": ["ê¸°íšŒ1"],
    "time_horizon": "short ë˜ëŠ” medium ë˜ëŠ” long"
}}"""
        
        payload = {
            "contents": [{
                "parts": [{"text": prompt}]
            }]
        }
        
        print(f"         ğŸŒ API URL: {self.gemini_api_url[:50]}...")
        print(f"         ğŸ“¤ ìš”ì²­ ì „ì†¡ ì¤‘...")
        
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(self.gemini_api_url, json=payload)
                print(f"         ğŸ“¥ ì‘ë‹µ ìˆ˜ì‹  - Status: {response.status_code}")
                
                if response.status_code == 200:
                    result = response.json()
                    print(f"         ğŸ“„ ì‘ë‹µ ë‚´ìš©: {str(result)[:200]}...")
                    
                    if 'candidates' in result and result['candidates']:
                        content = result['candidates'][0]['content']['parts'][0]['text']
                        
                        # JSON ì¶”ì¶œ
                        match = re.search(r'\{.*\}', content, re.DOTALL)
                        if match:
                            try:
                                sentiment_data = json.loads(match.group(0))
                                # ì›ë³¸ ë°ì´í„°ì˜ ëª¨ë“  í•„ë“œë¥¼ ë³´ì¡´í•˜ë©´ì„œ ê°ì • ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                                result = original_item.copy() if original_item else {"text": text}
                                # scoreì™€ confidence ì•ˆì „í•˜ê²Œ ë³€í™˜
                                score_value = sentiment_data.get("score", 0)
                                if score_value is None:
                                    score_value = 0
                                confidence_value = sentiment_data.get("confidence", 0.5)
                                if confidence_value is None:
                                    confidence_value = 0.5
                                    
                                result.update({
                                    "source": source,
                                    "summary": sentiment_data.get("summary", "ìš”ì•½ ì—†ìŒ"),
                                    "score": float(score_value),
                                    "confidence": float(confidence_value),
                                    "financial_impact": sentiment_data.get("financial_impact", "medium"),
                                    "key_topics": sentiment_data.get("key_topics", []),
                                    "risk_factors": sentiment_data.get("risk_factors", []),
                                    "opportunities": sentiment_data.get("opportunities", []),
                                    "time_horizon": sentiment_data.get("time_horizon", "medium")
                                })
                                return result
                            except json.JSONDecodeError as e:
                                print(f"         âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                                print(f"         ğŸ“„ ì›ë³¸ ë‚´ìš©: {content[:200]}...")
                else:
                    print(f"         âŒ API ì˜¤ë¥˜ - Status: {response.status_code}")
                    print(f"         ğŸ“„ ì˜¤ë¥˜ ì‘ë‹µ: {response.text[:200]}...")
                    
        except httpx.TimeoutException:
            print("         â±ï¸ API íƒ€ì„ì•„ì›ƒ (30ì´ˆ)")
        except Exception as e:
            print(f"         âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜ (ì›ë³¸ ë°ì´í„° ë³´ì¡´)
        result = original_item.copy() if original_item else {}
        result.update({
            "text": text[:200] + "..." if len(text) > 200 else text,
            "source": source,
            "summary": "ë¶„ì„ ì‹¤íŒ¨",
            "score": 0.0
        })
        return result

# ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
agent = SentimentAnalysisAgentV2()

# BaseAgentì˜ appì„ ì‚¬ìš©
app = agent.app

# ì¶”ê°€ ì—”ë“œí¬ì¸íŠ¸
@app.get("/agent/status")
async def agent_status():
    """ì—ì´ì „íŠ¸ ìƒíƒœ"""
    return {
        "name": agent.name,
        "agent_id": agent.agent_id,
        "status": "active",
        "capabilities": agent.capabilities,
        "gemini_configured": bool(agent.gemini_api_key)
    }

# ì•± ì‹œì‘ ì‹œ ì—ì´ì „íŠ¸ ì‹œì‘
@app.on_event("startup")
async def startup():
    print("ğŸš€ Sentiment Analysis Agent V2 ì‹œì‘ ì¤‘...")
    await agent.start()

# ì•± ì¢…ë£Œ ì‹œ ì—ì´ì „íŠ¸ ì •ë¦¬
@app.on_event("shutdown")
async def shutdown():
    await agent.stop()

if __name__ == "__main__":
    # uvicornìœ¼ë¡œ ì§ì ‘ ì‹¤í–‰
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8202)